{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect ICD9/10 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import tqdm\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import math\n",
    "from IPython.display import display, HTML\n",
    "from datetime import date\n",
    "import multiprocessing\n",
    "\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the workspace bucket and CDR directory; this command will be repeated in most analyses in this repository\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "my_bucket\n",
    "CDR_version=os.getenv(\"WORKSPACE_CDR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important files for phecode annotation\n",
    "sex_at_birth_restriction=pd.read_csv(f'{my_bucket}/data/phewas/sex_at_birth_restriction.csv')\n",
    "sex_at_birth_restriction.head(5)\n",
    "\n",
    "phecodes=pd.read_csv(f'{my_bucket}/data/phewas/ICDPhecodes')\n",
    "phecodes.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# This query represents dataset \"ced2\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_04499009_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person   \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (836793) \n",
    "                                AND is_standard = 0  \n",
    "                                AND  value_source_concept_id IN (1384519)\n",
    "                            )) criteria \n",
    "                    UNION\n",
    "                    ALL SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (\n",
    "                                    SELECT\n",
    "                                        DISTINCT c.concept_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                    JOIN\n",
    "                                        (\n",
    "                                            select\n",
    "                                                cast(cr.id as string) as id \n",
    "                                            FROM\n",
    "                                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                            WHERE\n",
    "                                                concept_id IN (194992) \n",
    "                                                AND full_text LIKE '%_rank1]%'\n",
    "                                        ) a \n",
    "                                            ON (\n",
    "                                                c.path LIKE CONCAT('%.',\n",
    "                                            a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path LIKE CONCAT('%.',\n",
    "                                            a.id) \n",
    "                                            OR c.path LIKE CONCAT(a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path = a.id) \n",
    "                                        WHERE\n",
    "                                            is_standard = 1 \n",
    "                                            AND is_selectable = 1\n",
    "                                        ) \n",
    "                                        AND is_standard = 1 \n",
    "                                )\n",
    "                            ) criteria \n",
    "                        ) )\"\"\"\n",
    "\n",
    "ced_person = pd.read_gbq(\n",
    "    dataset_04499009_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "ced_person.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ced_person['celiac']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now find everyone without CeD\n",
    "# amend to include people with icd9cm and icd10 cm in observation\n",
    "# use df_smoke_controls_exclusion person_ids since we don't want anyone with chewing tobacco in controls\n",
    "query = (\"\"\"\n",
    "select distinct person_id from `\"\"\"+ str(CDR_version)+\"\"\".condition_occurrence`\n",
    "where person_id not in \"\"\"+\"(\"+' '.join([str(id)+\",\" for id in np.unique(ced_person.person_id)])[:-1]+\")\"+\"\"\";\n",
    "\"\"\")\n",
    "no_cel = pd.read_gbq(query, dialect=\"standard\")\n",
    "# people with at least one icd9/10cm code in observation but no smoking code (including chewing tobacco)\n",
    "# so use df_smoke_controls_exclusion person_ids\n",
    "# deduplicate the person_ids\n",
    "query = (\"\"\"\n",
    "SELECT distinct person_id\n",
    "FROM \n",
    "    (SELECT DISTINCT person_id, observation_source_concept_id, observation_source_value, observation_date\n",
    "        FROM `\"\"\"+ str(CDR_version) +\"\"\".observation`) AS obs\n",
    "     INNER JOIN \n",
    "        (SELECT DISTINCT concept_id, concept_name, concept_code, vocabulary_id \n",
    "            FROM `\"\"\"+str(CDR_version)+\"\"\".concept`\n",
    "            where (vocabulary_id ='ICD9CM') or \n",
    "            (vocabulary_id ='ICD10CM')) as concept \n",
    "            on concept.concept_id = obs.observation_source_concept_id\n",
    "       where person_id not in \"\"\"+\"(\"+' '.join([str(id)+\",\" for id in np.unique(ced_person.person_id)])[:-1]+\")\"+\"\"\"\n",
    "\"\"\")\n",
    "observation_coded_participants_no_cel = pd.read_gbq(query, dialect=\"standard\")\n",
    "\n",
    "# append to cel_nos from condition occurrence\n",
    "no_cel = pd.concat([no_cel,observation_coded_participants_no_cel])\n",
    "# deduplicate \n",
    "no_cel = no_cel.drop_duplicates()\n",
    "no_cel[\"celiac\"] = 0\n",
    "\n",
    "ced_ehr = pd.concat([ced_person, no_cel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ced_ehr.value_counts('celiac')\n",
    "#254777 healhty, 3040 CeD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## query for covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "def age(birthdate,enrolldate):\n",
    "    age = enrolldate.year - birthdate.year - ((enrolldate.month, enrolldate.day) < (birthdate.month, birthdate.day))\n",
    "    return age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_covariates(df_indep_var,CDR_version):\n",
    "    # first query from condition occurrence to get number of distinct codes and ehr length\n",
    "    query=\"\"\"SELECT person_id, min(condition_start_date) as min_cond_date,max(condition_start_date)as max_cond_date,COUNT(DISTINCT condition_concept_id) as cond_code_cnt \n",
    "    FROM `\"\"\"+CDR_version+\"\"\".condition_occurrence` WHERE condition_start_date >='1980-01-01'\n",
    "    GROUP BY person_id \"\"\"\n",
    "\n",
    "    ehr_covariate=pd.read_gbq(query, dialect=\"standard\")\n",
    "    # EHR Length is a bit subtle here. Observation date is a little tricky because birthdate is used in observation. \n",
    "    # What we need to do is take the relevant codes from observation and find the minimum and maximum dates overall\n",
    "    query = (\"\"\"\n",
    "        SELECT distinct person_id, min(observation_date) as min_obs_date, max(observation_date) as max_obs_date, COUNT(DISTINCT observation_concept_id) as observation_code_cnt \n",
    "        FROM \n",
    "            (SELECT DISTINCT person_id, observation_source_concept_id, observation_source_value, observation_date, observation_concept_id\n",
    "                FROM `\"\"\"+ str(CDR_version) +\"\"\".observation`) AS obs\n",
    "             INNER JOIN \n",
    "                (SELECT DISTINCT concept_id, concept_name, concept_code, vocabulary_id \n",
    "                    FROM `\"\"\"+str(CDR_version)+\"\"\".concept`\n",
    "                    where (vocabulary_id ='ICD9CM') or \n",
    "                    (vocabulary_id ='ICD10CM')) as concept \n",
    "                    on concept.concept_id = obs.observation_source_concept_id\n",
    "        group by person_id\n",
    "        \"\"\")\n",
    "    observation_code_dates = pd.read_gbq(query, dialect=\"standard\")\n",
    "    # note, this procedure takes into consideration NaTs, so if a person didn't have an observation code, it will\n",
    "    ehr_covariate_plus = pd.merge(observation_code_dates, ehr_covariate, on=\"person_id\", how = 'outer')\n",
    "    # automatically take the minimum condition occurrence date.\n",
    "    ehr_covariate_plus[\"min_date\"] = [ehr_covariate_plus[[\"min_obs_date\",\"min_cond_date\"]].loc[i].min() for i in ehr_covariate_plus.index]\n",
    "    ehr_covariate_plus[\"max_date\"] = [ehr_covariate_plus[[\"max_obs_date\",\"max_cond_date\"]].loc[i].max() for i in ehr_covariate_plus.index]\n",
    "    ehr_covariate_plus[\"code_cnt\"] =  ehr_covariate_plus[[\"cond_code_cnt\",\"observation_code_cnt\"]].sum(axis =1)\n",
    "    # for efficiency sake drop the extra columns\n",
    "    ehr_covariate_plus = ehr_covariate_plus.drop(columns = [\"min_obs_date\",\"min_cond_date\",\"max_obs_date\",\"max_cond_date\",\"cond_code_cnt\",\"observation_code_cnt\"])\n",
    "    # ehr length defined as time between minimum of relevant observation dates  \n",
    "    ehr_covariate_plus[\"ehr_length\"]=(ehr_covariate_plus['max_date']-ehr_covariate_plus['min_date']).apply(lambda x:x).dt.days\n",
    "\n",
    "    # Now Demographics\n",
    "    \n",
    "    query=\"\"\"SELECT DISTINCT p.person_id,sex_at_birth_concept_id,gender_concept_id,race_concept_id,ethnicity_concept_id,birth_datetime FROM \n",
    "    `\"\"\"+CDR_version+\"\"\".person` p \n",
    "    \"\"\"\n",
    "    demo_patients=pd.read_gbq(query, dialect=\"standard\")\n",
    "    print(demo_patients)\n",
    "    demo_patients[\"age_today\"] = (datetime.now(tz=timezone.utc)-demo_patients[\"birth_datetime\"])/np.timedelta64(1,'Y')\n",
    "    demo_patients=demo_patients[demo_patients[\"person_id\"].isin(df_indep_var[\"person_id\"])]\n",
    "    \n",
    "    # tidy up \n",
    "    #demo_patients_merge = demo_patients\n",
    "    #demo_patients_merge=pd.merge(demo_patients, race_generalized,on=\"person_id\")\n",
    "    demo_patients_merge=pd.merge(demo_patients, ehr_covariate_plus, on=\"person_id\") # now merge to other ehr covariates # amended 04/17/2020\n",
    "    demo_patients_merge[\"age_at_last_event\"] = (pd.to_datetime(demo_patients_merge['max_date'],utc=True)-demo_patients_merge[\"birth_datetime\"])/np.timedelta64(1,'Y')\n",
    "    \n",
    "    #############\n",
    "    #race\n",
    "    #############\n",
    "    white = 8527\n",
    "    black_aa = 8516\n",
    "    asian = 8515\n",
    "    # other \n",
    "    more_than_one = 2000000008\n",
    "    none_of_these = 45882607\n",
    "    another_single_pop=2000000001\n",
    "    other = [more_than_one, none_of_these,another_single_pop]\n",
    "    #Unknown\n",
    "    prefer_not_answer = 1177221\n",
    "    skip = 903096\n",
    "    no_match = 0\n",
    "    unknown_race = [prefer_not_answer, skip, no_match]\n",
    "    ## update indicators\n",
    "    demo_patients_merge[\"white\"]=[0]*demo_patients_merge.shape[0]\n",
    "    demo_patients_merge[\"AF\"]=[0]*demo_patients_merge.shape[0]\n",
    "    demo_patients_merge[\"Asian\"]=[0]*demo_patients_merge.shape[0]\n",
    "    demo_patients_merge[\"race_unk\"]=[0]*demo_patients_merge.shape[0]\n",
    "    demo_patients_merge[\"Other\"]=[0]*demo_patients_merge.shape[0]\n",
    "    \n",
    "    demo_patients_merge.loc[demo_patients_merge[\"race_concept_id\"]==white,\"white\"]=1\n",
    "    demo_patients_merge.loc[demo_patients_merge[\"race_concept_id\"]==black_aa,\"AF\"]=1\n",
    "    demo_patients_merge.loc[demo_patients_merge[\"race_concept_id\"]==asian,\"Asian\"]=1\n",
    "    demo_patients_merge.loc[demo_patients_merge[\"race_concept_id\"].isin(unknown_race),\"race_unk\"]=1\n",
    "    demo_patients_merge.loc[demo_patients_merge[\"race_concept_id\"].isin(other),\"Other\"]=1\n",
    "\n",
    "    \n",
    "    #############\n",
    "    #ethnicity\n",
    "    #############\n",
    "    #hisp/latino\n",
    "    hisp_latino = 38003563\n",
    "    # not hisp/latino\n",
    "    not_hisp_lat = 38003564\n",
    "    none_of_these = 45882607\n",
    "    not_hisp = [not_hisp_lat, none_of_these]\n",
    "    # unknown\n",
    "    prefer_no_ans = 1177221\n",
    "    skip= 903096\n",
    "    unknown_eth = [prefer_no_ans, skip]\n",
    "    # update indicators \n",
    "    \n",
    "    demo_patients_merge[\"hisp_lat\"]=[0]*demo_patients_merge.shape[0]\n",
    "    demo_patients_merge[\"not_hisp_lat\"]=[0]*demo_patients_merge.shape[0]\n",
    "    demo_patients_merge[\"unk_eth\"]=[0]*demo_patients_merge.shape[0]\n",
    "    # sex at birth \n",
    "    demo_patients_merge.loc[ demo_patients_merge[\"ethnicity_concept_id\"]==hisp_latino,\"hisp_lat\"]=1\n",
    "    demo_patients_merge.loc[ demo_patients_merge[\"ethnicity_concept_id\"]==not_hisp_lat,\"not_hisp_lat\"]=1\n",
    "    demo_patients_merge.loc[(demo_patients_merge[\"ethnicity_concept_id\"].isin(unknown_eth)),\"unk_eth\"]=1\n",
    "    \n",
    "    \n",
    "    #############\n",
    "    #sex at birth\n",
    "    #############\n",
    "    female = 45878463\n",
    "    male = 45880669\n",
    "    unknown = 2000000009 # prefer not to answer\n",
    "    zer = 0\n",
    "    ## update indicators\n",
    "    demo_patients_merge[\"female\"]=[0]*demo_patients_merge.shape[0]\n",
    "    demo_patients_merge[\"male\"]=[0]*demo_patients_merge.shape[0]\n",
    "    demo_patients_merge[\"unk_sex\"]=[0]*demo_patients_merge.shape[0]\n",
    "    # sex at birth \n",
    "    demo_patients_merge.loc[demo_patients_merge[\"sex_at_birth_concept_id\"]==female,\"female\"]=1\n",
    "    demo_patients_merge.loc[demo_patients_merge[\"sex_at_birth_concept_id\"]==male,\"male\"]=1\n",
    "    demo_patients_merge.loc[(demo_patients_merge[\"sex_at_birth_concept_id\"]==unknown)|\n",
    "                            (demo_patients_merge[\"sex_at_birth_concept_id\"]==zer),\"unk_sex\"]=1\n",
    "    # now merge to the indep var of interest \n",
    "    demo_patients_cov=pd.merge(demo_patients_merge,df_indep_var, on = \"person_id\")\n",
    "    demo_patients_cov=demo_patients_cov.drop_duplicates()\n",
    "    return(demo_patients_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_patients_cov = make_covariates(ced_ehr, CDR_version = CDR_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_patients_cov.to_csv(f'demo_patients_v2.csv',index=False)\n",
    "demo_patients_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_patients_cov = pd.read_csv(f'{my_bucket}/data/phewas/demo_patients_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_patients_cov.value_counts('celiac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map ICD codes to phecodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# More specific icd9 and 10 querying\n",
    "def getPhecodeParticipants(phecodes_list, CDR_version, num_processes):\n",
    "    \"\"\"\n",
    "    Batching function for parallel extraction of participant Phecodes \n",
    "    ======================================================================================================\n",
    "    phecodes_batch: Pandas Dataframe of Phecodes \n",
    "    return_dict: \n",
    "    phecodes_list: List of phecodes to process \n",
    "    CDR_version: String of current cdr version \n",
    "    ## need to include rollup \n",
    "    \"\"\"\n",
    "    size = int(np.ceil(len(phecodes_list)/num_processes))\n",
    "    phecodes=ICD9_IC10_Phecodes[ICD9_IC10_Phecodes[\"phecode\"].isin(phecodes_list)]\n",
    "    \n",
    "    ## ICD Codes in condition_occurrence (if a code is in observation, then it shouldn't query anything here)\n",
    "    icd9_codes_cond=phecodes[phecodes['vocabulary_id']=='ICD9CM'][\"code\"].tolist()\n",
    "    #\n",
    "    icd9_codes_cond_str=\"'\"+\"','\".join(icd9_codes_cond)+\"'\"\n",
    "    \n",
    "    icd10_codes_cond=phecodes[phecodes['vocabulary_id']=='ICD10CM'][\"code\"].tolist()\n",
    "    icd10_codes_cond_str=\"'\"+\"','\".join(icd10_codes_cond)+\"'\"\n",
    "    \n",
    "    ## ICD Codes in observation \n",
    "    \n",
    "    icd9_codes_obs=phecodes[phecodes['vocabulary_id']=='ICD9CM'][\"code\"].tolist()\n",
    "    #\n",
    "    icd9_codes_obs_str=\"'\"+\"','\".join(icd9_codes_obs)+\"'\"\n",
    "    \n",
    "    icd10_codes_obs=phecodes[phecodes['vocabulary_id']=='ICD10CM'][\"code\"].tolist()\n",
    "    icd10_codes_obs_str=\"'\"+\"','\".join(icd10_codes_obs)+\"'\"\n",
    "    \n",
    "    # there's a subtlety here that we need icd10 cm\n",
    "    query=\"\"\"SELECT DISTINCT icd.person_id,condition_start_date as start_date,condition_concept_id as cid,concept_code,vocabulary_id FROM `\"\"\"+CDR_version+\"\"\".concept` \n",
    "    c  INNER JOIN `\"\"\"+CDR_version+\"\"\".condition_occurrence` icd  ON icd.condition_source_concept_id=c.concept_id  \n",
    "    WHERE vocabulary_id ='ICD9CM' AND  concept_code IN (\"\"\"+icd9_codes_cond_str+\"\"\") \n",
    "    ORDER BY condition_start_date\"\"\"\n",
    "    icdcodes1_cond=pd.read_gbq(query, dialect=\"standard\",use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),progress_bar_type=\"tqdm_notebook\")\n",
    "    query=\"\"\"SELECT DISTINCT icd.person_id,condition_start_date as start_date,condition_concept_id as cid,concept_code, vocabulary_id FROM `\"\"\"+CDR_version+\"\"\".concept` \n",
    "    c  INNER JOIN `\"\"\"+CDR_version+\"\"\".condition_occurrence` icd  ON c.concept_id = icd.condition_source_concept_id  \n",
    "    WHERE vocabulary_id ='ICD10CM' AND  concept_code IN (\"\"\"+icd10_codes_cond_str+\"\"\")\n",
    "    ORDER BY condition_start_date\"\"\"\n",
    "    icdcodes2_cond=pd.read_gbq(query, dialect=\"standard\",use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),progress_bar_type=\"tqdm_notebook\")\n",
    "    \n",
    "    #Now observations \n",
    "    \n",
    "    query=\"\"\"SELECT DISTINCT icd.person_id,observation_date as start_date, observation_concept_id as cid,concept_code,vocabulary_id FROM `\"\"\"+CDR_version+\"\"\".concept` \n",
    "    c  INNER JOIN `\"\"\"+CDR_version+\"\"\".observation` icd  ON icd.observation_source_concept_id=c.concept_id  \n",
    "    WHERE vocabulary_id ='ICD9CM' AND  concept_code IN (\"\"\"+icd9_codes_obs_str+\"\"\") \n",
    "    ORDER BY start_date\"\"\"\n",
    "    icdcodes1_obs=pd.read_gbq(query, dialect=\"standard\",progress_bar_type=\"tqdm_notebook\")\n",
    "    query=\"\"\"SELECT DISTINCT icd.person_id,observation_date as start_date,observation_concept_id as cid, concept_code, vocabulary_id FROM `\"\"\"+CDR_version+\"\"\".concept` \n",
    "    c  INNER JOIN `\"\"\"+CDR_version+\"\"\".observation` icd  ON c.concept_id = icd.observation_source_concept_id  \n",
    "    WHERE vocabulary_id ='ICD10CM' AND  concept_code IN (\"\"\"+icd10_codes_obs_str+\"\"\")\n",
    "    ORDER BY start_date\"\"\"\n",
    "    \n",
    "    icdcodes2_obs=pd.read_gbq(query, dialect=\"standard\",progress_bar_type=\"tqdm_notebook\")\n",
    "    \n",
    "    icdcodes=pd.concat([icdcodes1_cond,icdcodes2_cond,icdcodes1_obs,icdcodes2_obs]).drop_duplicates() # drop duplicates within vocab, person id and date\n",
    "\n",
    "    patients_phcode_count=icdcodes[[\"person_id\",\"start_date\",\"concept_code\",\"vocabulary_id\"]].drop_duplicates()[[\"person_id\",\"concept_code\",\"start_date\",\"vocabulary_id\"]]\n",
    "\n",
    "    patients_phcode_count=pd.merge(phecodes[[\"code\",\"phecode\",\"vocabulary_id\"]],patients_phcode_count,left_on=[\"code\", \"vocabulary_id\"],right_on=[\"concept_code\", \"vocabulary_id\"])\n",
    "\n",
    "    return patients_phcode_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICD9_IC10_Phecodes=pd.read_csv(f\"{my_bucket}/data/phewas/phecode_map_icd9_10.csv\")\n",
    "# strip off extra column \n",
    "ICD9_IC10_Phecodes = ICD9_IC10_Phecodes.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phecodes_list=ICD9_IC10_Phecodes[\"phecode\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict={}\n",
    "phecodes_patients_list=getPhecodeParticipants(1, phecodes_list, CDR_version, 235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollup_map=pd.read_csv('phecode_rollup_map.csv')\n",
    "rollup_map\n",
    "\n",
    "phecodes_patients_list_merge = pd.merge(rollup_map, phecodes_patients_list,left_on = 'code', right_on = 'phecode')[[\"person_id\",\"phecode_unrolled\",\"start_date\"]].drop_duplicates()\n",
    "\n",
    "phecodes_patients_counts_tmp=phecodes_patients_list_merge[[\"person_id\",\"phecode_unrolled\",\"start_date\"]].groupby([\"person_id\",\"phecode_unrolled\"],as_index=False).count()\n",
    "\n",
    "phecodes_patients_counts_tmp.columns = [\"person_id\", \"phecode\", 'count']\n",
    "\n",
    "phecodes_patients_counts_tmp.to_csv(f'{my_bucket}/data/phewas/phecodes_patient_counts.csv',index=False)\n",
    "\n",
    "phecodes_patients_counts_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phecodes_patients_counts = pd.read_csv(f'{my_bucket}/data/phewas/phecodes_patient_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine everything and define phewas object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update to sex_specific phecodes \n",
    "\n",
    "class PheWAS_Pool:\n",
    "    \"\"\"\n",
    "    Class for performing PheWAS\n",
    "    ======================================================================================================\n",
    "    phecode_counts: Pandas Dataframe of Phecodes \n",
    "    covariates: Pandas Dataframe of covariates to include in the analysis\n",
    "    indep_var: String indicating the column in covariates that is the independent variable of interest\n",
    "    CDR_version: String indicating CDR version\n",
    "    phecode_process: list for phecodes to process\n",
    "    min_cases: minimum number of cases for an individual phenotype to be analyzed\n",
    "    cores: if not \"\", then specify number of cores to use in the analysis \n",
    "    \"\"\"\n",
    "    def __init__(self, phecode_counts,\n",
    "                 covariates, \n",
    "                 indep_var_of_interest=\"\", \n",
    "                 CDR_version='R2019Q4R3',\n",
    "                 phecode_process = 'all', \n",
    "                 min_cases = 100,\n",
    "                 independent_var_names=[\"AF\",\"white\",\"Asian\",\"male\",\"age_at_last_event\",\n",
    "                                        \"ehr_length\",\"code_cnt\", \"unk_sex\", \"race_unk\", \"hisp_lat\",\"unk_eth\"],\n",
    "                 genderspec_independent_var_names=[\"AF\",\"white\",\"Asian\",\"age_at_last_event\",\"unk_sex\",\"male\",\n",
    "                                                   \"ehr_length\",\"code_cnt\",\"race_unk\",\"hisp_lat\",\"unk_eth\"],\n",
    "                 show_res = False,\n",
    "                 cores=\"\"):\n",
    "        print(\"~~~~~~~~~~~~~~~        Creating PheWAS AOU Object           ~~~~~~~~~~~~~~~~~~~~~\")\n",
    "        # create instance attributes\n",
    "        self.indep_var_of_interest = indep_var_of_interest\n",
    "        #update 09_5_2019: only process phecodes passed in phecode counts\n",
    "        if phecode_process =='all':\n",
    "            self.phecode_list = phecode_counts[\"phecode\"].unique().tolist()\n",
    "        else:\n",
    "            self.phecode_list = phecode_process\n",
    "        self.CDR_version = CDR_version\n",
    "        self.cores = cores \n",
    "        print(\"~~~~~~~~~~~~~~~       Merging Phecodes and Covariates       ~~~~~~~~~~~~~~~~~~~~~\")\n",
    "        self.demo_patients_phecodes = pd.merge(covariates,phecode_counts, on = [\"person_id\"])\n",
    "        self.show_res = show_res\n",
    "        self.independent_var_names = independent_var_names\n",
    "        self.independent_var_names= list(np.append(np.array([self.indep_var_of_interest]),self.independent_var_names))  \n",
    "        self.genderspec_independent_var_names = genderspec_independent_var_names\n",
    "        self.genderspec_independent_var_names= list(np.append(np.array([self.indep_var_of_interest]),self.genderspec_independent_var_names))  \n",
    "        self.remove_dup = list(np.append(np.array([\"person_id\"]),self.independent_var_names))\n",
    "        self.min_cases = min_cases \n",
    "        \n",
    "    def runPheLogit(self, phecodes): \n",
    "        #placeholder\n",
    "        temp=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an object of class PheWAS for FULL PheWAS\n",
    "test_pool = PheWAS_Pool(phecode_counts = phecodes_patients_counts,\n",
    "              covariates= demo_patients_cov, CDR_version= CDR_version,indep_var_of_interest=\"celiac\",\n",
    "             independent_var_names=[\"AF\",\"white\",\"Asian\",\"male\",\"age_at_last_event\",\"ehr_length\",\"code_cnt\", \"unk_sex\", \"race_unk\", \"hisp_lat\",\"unk_eth\"],\n",
    "            genderspec_independent_var_names=[\"AF\",\"white\",\"Asian\",\"age_at_last_event\",\"ehr_length\",\"code_cnt\",\"race_unk\",\"hisp_lat\",\"unk_eth\"],\n",
    "              phecode_process = 'all',show_res = True,\n",
    "              cores =16,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('phewas_pool_v2.pkl', 'wb') as outp:\n",
    "    pickle.dump(test_pool, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
