{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"ced2\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_70171923_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (836793) \n",
    "                                AND is_standard = 0  \n",
    "                                AND  value_source_concept_id IN (1384519)\n",
    "                            )) criteria \n",
    "                    UNION\n",
    "                    ALL SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (\n",
    "                                    SELECT\n",
    "                                        DISTINCT c.concept_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                    JOIN\n",
    "                                        (\n",
    "                                            select\n",
    "                                                cast(cr.id as string) as id \n",
    "                                            FROM\n",
    "                                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                            WHERE\n",
    "                                                concept_id IN (194992) \n",
    "                                                AND full_text LIKE '%_rank1]%'\n",
    "                                        ) a \n",
    "                                            ON (\n",
    "                                                c.path LIKE CONCAT('%.',\n",
    "                                            a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path LIKE CONCAT('%.',\n",
    "                                            a.id) \n",
    "                                            OR c.path LIKE CONCAT(a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path = a.id) \n",
    "                                        WHERE\n",
    "                                            is_standard = 1 \n",
    "                                            AND is_selectable = 1\n",
    "                                        ) \n",
    "                                        AND is_standard = 1 \n",
    "                                )\n",
    "                            ) criteria \n",
    "                        ) )\"\"\"\n",
    "\n",
    "celiac_person_df = pandas.read_gbq(\n",
    "    dataset_70171923_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "celiac_person_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"controls2\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_06882751_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 \n",
    "                ) \n",
    "                AND cb_search_person.person_id NOT IN (\n",
    "                    SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (\n",
    "                                    SELECT\n",
    "                                        DISTINCT c.concept_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                    JOIN\n",
    "                                        (\n",
    "                                            select\n",
    "                                                cast(cr.id as string) as id \n",
    "                                            FROM\n",
    "                                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                            WHERE\n",
    "                                                concept_id IN (197225, 40492037, 4300555, 44782478, 45770902, 435228, 443390, 46269847, 443400, 40493020, 45773688, 4177101, 443386, 4313634, 4224254, 4177112, 433171, 78987, 4155297, 320342, 40482469, 40491001, 45769830, 40479837, 4241917, 4003693, 4295624, 4112974, 192855, 40484648, 4312290, 4342656, 4298033, 441805, 4112745, 36676291, 4074815, 37396808, 45768522, 4181343, 40488919, 45757101, 4180795, 4178974, 4294416, 4233629, 4298028, 4029372, 46273478, 439125, 42535540, 444411, 4181338, 4298026, 4178968, 4181488, 45757266, 4246451, 4214901, 4178977, 4241904, 4312288, 4095312, 4315802, 40481367, 4143857, 4178959, 443391, 258369, 434875, 4313482, 438386, 4297185, 4180790, 4309851, 4180784, 318096, 75580, 194992, 4180779, 4006586, 4116142, 4180910, 4297666, 37108693, 442183, 373425, 201240, 45757507, 4180791, 81893, 40490993, 40487143, 40490995, 4177230, 4112853, 4291454, 37016767, 201254, 4331508, 443412, 194077, 46269846, 40487047, 4298032, 4312023, 75512, 75210, 443392, 4297665, 4225656, 46269839, 4309225, 4178976, 133726, 435216, 438095, 45767622, 45769873, 4177488, 72266, 46269848, 4246450, 4307538, 195513, 764225, 443389, 46269840, 442139, 195197, 43531009, 4092524, 4116087, 4001170, 40493428, 4281109, 25189, 443387, 433143, 40490994, 433435, 194684, 40484649, 40483293, 37109046, 201531, 4001666, 37018566, 40486175, 43531008, 24897, 4181351, 4246127, 4163333, 4307263, 40492021, 4166480, 46270738, 4177243, 442181, 4297668, 37117053, 195585, 4228112, 444410, 436671, 46269850, 4003027, 46269921, 46269843, 4180780, 4178971, 4181483, 4241905, 255507, 439727, 4181354, 4128019, 35626069, 4225055, 35624485, 4308621, 192581, 443388, 4247238, 133444, 201606, 4110861, 4180793, 254591, 4178964) \n",
    "                                                AND full_text LIKE '%_rank1]%'\n",
    "                                        ) a \n",
    "                                            ON (\n",
    "                                                c.path LIKE CONCAT('%.',\n",
    "                                            a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path LIKE CONCAT('%.',\n",
    "                                            a.id) \n",
    "                                            OR c.path LIKE CONCAT(a.id,\n",
    "                                            '.%') \n",
    "                                            OR c.path = a.id) \n",
    "                                        WHERE\n",
    "                                            is_standard = 1 \n",
    "                                            AND is_selectable = 1\n",
    "                                        ) \n",
    "                                        AND is_standard = 1 \n",
    "                                )\n",
    "                            ) criteria \n",
    "                        UNION\n",
    "                        ALL SELECT\n",
    "                            criteria.person_id \n",
    "                        FROM\n",
    "                            (SELECT\n",
    "                                DISTINCT person_id,\n",
    "                                entry_date,\n",
    "                                concept_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                            WHERE\n",
    "                                (\n",
    "                                    concept_id IN (836793) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (1384519) \n",
    "                                    OR  concept_id IN (836768) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43528472) \n",
    "                                    OR  concept_id IN (836770) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43528480) \n",
    "                                    OR  concept_id IN (836771) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43528492) \n",
    "                                    OR  concept_id IN (836772) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43528500) \n",
    "                                    OR  concept_id IN (836831) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43528565) \n",
    "                                    OR  concept_id IN (836832) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43528668) \n",
    "                                    OR  concept_id IN (836833) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43528679) \n",
    "                                    OR  concept_id IN (836834) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43528886) \n",
    "                                    OR  concept_id IN (836776) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43529136) \n",
    "                                    OR  concept_id IN (836777) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43529184) \n",
    "                                    OR  concept_id IN (836779) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43529684) \n",
    "                                    OR  concept_id IN (836780) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43529733) \n",
    "                                    OR  concept_id IN (836781) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43529817) \n",
    "                                    OR  concept_id IN (836783) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43529909) \n",
    "                                    OR  concept_id IN (836796) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (1384604) \n",
    "                                    OR  concept_id IN (1740630) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (1384594) \n",
    "                                    OR  concept_id IN (836799) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (43529923) \n",
    "                                    OR  concept_id IN (1384662) \n",
    "                                    AND is_standard = 0  \n",
    "                                    AND  value_source_concept_id IN (1384391)\n",
    "                                )) criteria ) \n",
    "                    )\"\"\"\n",
    "\n",
    "control_person_df = pandas.read_gbq(\n",
    "    dataset_06882751_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "control_person_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "bucket = os.getenv('WORKSPACE_BUCKET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## age calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract enrollment date\n",
    "dataset_ages_sql = \"\"\"SELECT DISTINCT\n",
    "\n",
    "person_id,\n",
    "\n",
    "observation_datetime AS primary_consent_date\n",
    "\n",
    "FROM `fc-aou-cdr-prod-ct.C2022Q4R11.concept`\n",
    "\n",
    "JOIN `fc-aou-cdr-prod-ct.C2022Q4R11.concept_ancestor` on concept_id = ancestor_concept_id\n",
    "\n",
    "JOIN `fc-aou-cdr-prod-ct.C2022Q4R11.observation` on descendant_concept_id = observation_concept_id\n",
    "\n",
    "WHERE concept_name = 'Consent PII' AND concept_class_id = 'Module'\"\"\"\n",
    "\n",
    "ages_df = pandas.read_gbq(\n",
    "    dataset_ages_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "ages_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celiac_df = pandas.merge(celiac_person_df, ages_df, on='person_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls_df = pandas.merge(control_person_df, ages_df, on='person_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "def age(birthdate,enrolldate):\n",
    "    age = enrolldate.year - birthdate.year - ((enrolldate.month, enrolldate.day) < (birthdate.month, birthdate.day))\n",
    "    return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls_df['age'] = [age(i,j) for i,j in zip(tqdm(controls_df['date_of_birth']),tqdm(controls_df['primary_consent_date']))]\n",
    "celiac_df['age'] = [age(i,j) for i,j in zip(tqdm(celiac_df['date_of_birth']),tqdm(celiac_df['primary_consent_date']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare other covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp=['person_id','race','ethnicity','sex_at_birth','age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls_df=controls_df[comp]\n",
    "celiac_df=celiac_df[comp]\n",
    "celiac_df['label'] = 1\n",
    "controls_df['label'] = 0\n",
    "celiac_df.drop_duplicates('person_id',inplace=True)\n",
    "controls_df.drop_duplicates('person_id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(celiac_df)\n",
    "print(controls_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(celiac_df.value_counts('ethnicity'))\n",
    "print(controls_df.value_counts('ethnicity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(celiac_df.value_counts('race'))\n",
    "print(controls_df.value_counts('ethnicity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(celiac_df.value_counts('sex_at_birth'))\n",
    "print(controls_df.value_counts('sex_at_birth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.mean(controls_df.PC1))\n",
    "print(np.mean(celiac_df.PC1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(controls_df.age))\n",
    "print(np.mean(celiac_df.age))\n",
    "print(np.std(controls_df.age))\n",
    "print(np.std(celiac_df.age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "celiac_df.loc[~celiac_df['sex_at_birth'].isin(['Male', 'Female','Intersex']),'sex_at_birth']='other'\n",
    "celiac_df.loc[~celiac_df['race'].isin(['Native Hawaiian or Other Pacific Islander', 'White','Black or African American', 'Asian','Middle Eastern or North African']),'race']='other'\n",
    "celiac_df.loc[~celiac_df['ethnicity'].isin(['Not Hispanic or Latino', 'Hispanic or Latino']),'ethnicity']='other'\n",
    "\n",
    "controls_df.loc[~controls_df['sex_at_birth'].isin(['Male', 'Female','Intersex']),'sex_at_birth']='other'\n",
    "controls_df.loc[~controls_df['race'].isin(['Native Hawaiian or Other Pacific Islander', 'White','Black or African American', 'Asian','Middle Eastern or North African']),'race']='other'\n",
    "controls_df.loc[~controls_df['ethnicity'].isin(['Not Hispanic or Latino', 'Hispanic or Latino']),'ethnicity']='other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(celiac_df.value_counts('ethnicity'))\n",
    "print(controls_df.value_counts('ethnicity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(celiac_df.value_counts('race'))\n",
    "print(controls_df.value_counts('race'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(celiac_df.value_counts('sex_at_birth'))\n",
    "print(controls_df.value_counts('sex_at_birth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(celiac_df.value_counts('ancestry_pred'))\n",
    "print(controls_df.value_counts('ancestry_pred'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## propensity matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install --upgrade pip\n",
    "pip install pymatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pymatch import *\n",
    "import pymatch.functions as uf\n",
    "\n",
    "class Matcher:\n",
    "    \"\"\"\n",
    "    Matcher Class -- Match data for an observational study.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test : pd.DataFrame\n",
    "        Data representing the test group\n",
    "    control : (pd.DataFrame)\n",
    "        Data representing the control group\n",
    "    formula : str (optional)\n",
    "        custom formula to use for logistic regression\n",
    "        i.e. \"Y ~ x1 + x2 + ...\"\n",
    "    yvar : str (optional)\n",
    "        Name of dependent variable (the treatment)\n",
    "    exclude : list  (optional)\n",
    "        List of variables to ignore in regression/matching.\n",
    "        Useful for unique idenifiers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, test, control, yvar, formula=None, exclude=[]):\n",
    "        # configure plots for ipynb\n",
    "        plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "        # variables generated during matching\n",
    "        aux_match = ['scores', 'match_id', 'weight', 'record_id']\n",
    "        # assign unique indices to test and control\n",
    "        t, c = [i.copy().reset_index(drop=True) for i in (test, control)]\n",
    "        t = t.dropna(axis=1, how=\"all\")\n",
    "        c = c.dropna(axis=1, how=\"all\")\n",
    "        c.index += len(t)\n",
    "        self.data = pd.concat([t.dropna(axis=1, how='all'),(c.dropna(axis=1, how='all'))]).dropna()\n",
    "        self.control_color = \"#1F77B4\"\n",
    "        self.test_color = \"#FF7F0E\"\n",
    "        self.yvar = yvar\n",
    "        self.exclude = exclude + [self.yvar] + aux_match\n",
    "        self.formula = formula\n",
    "        self.nmodels = 1  # for now\n",
    "        self.models = []\n",
    "        self.swdata = None\n",
    "        self.model_accuracy = []\n",
    "        self.data[yvar] = self.data[yvar].astype(int)  # should be binary 0, 1\n",
    "        self.xvars = [i for i in self.data.columns if i not in self.exclude and i != yvar]\n",
    "        self.matched_data = []\n",
    "        self.y, self.X = patsy.dmatrices('{} ~ {}'.format(yvar, '+'.join(self.xvars)), data=self.data,\n",
    "                                         return_type='dataframe')\n",
    "        self.xvars = [i for i in self.data.columns if i not in self.exclude]\n",
    "        self.test= self.data[self.data[yvar] == True]\n",
    "        self.control = self.data[self.data[yvar] == False]\n",
    "        self.testn = len(self.test)\n",
    "        self.controln = len(self.control)\n",
    "        self.minority, self.majority = \\\n",
    "          [i[1] for i in sorted(zip([self.testn, self.controln], [1, 0]),\n",
    "                                key=lambda x: x[0])]\n",
    "        print('Formula:\\n{} ~ {}'.format(yvar, '+'.join(self.xvars)))\n",
    "        print('n majority:', len(self.data[self.data[yvar] == self.majority]))\n",
    "        print('n minority:', len(self.data[self.data[yvar] == self.minority]))\n",
    "\n",
    "    def fit_scores(self, balance=True, nmodels=None):\n",
    "        \"\"\"\n",
    "        Fits logistic regression model(s) used for\n",
    "        generating propensity scores\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        balance : bool\n",
    "            Should balanced datasets be used?\n",
    "            (n_control == n_test)\n",
    "        nmodels : int\n",
    "            How many models should be fit?\n",
    "            Score becomes the average of the <nmodels> models if nmodels > 1\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # reset models if refitting\n",
    "        if len(self.models) > 0:\n",
    "            self.models = []\n",
    "        if len(self.model_accuracy) > 0:\n",
    "            self.model_accuracy = []\n",
    "        if not self.formula:\n",
    "            # use all columns in the model\n",
    "            self.formula = '{} ~ {}'.format(self.yvar, '+'.join(self.xvars))\n",
    "        if balance:\n",
    "            if nmodels is None:\n",
    "                # fit multiple models based on imbalance severity (rounded up to nearest tenth)\n",
    "                minor, major = [self.data[self.data[self.yvar] == i] for i in (self.minority, self.majority)]\n",
    "                nmodels = int(np.ceil((len(major) / len(minor)) / 10) * 10)\n",
    "            self.nmodels = nmodels\n",
    "            i = 0\n",
    "            errors = 0\n",
    "#             while i < nmodels and errors < 5:\n",
    "            while i < nmodels:\n",
    "                uf.progress(i+1, nmodels,\n",
    "                            prestr=\"Fitting Models on Balanced Samples\")\n",
    "         \n",
    "                # sample from majority to create balance dataset\n",
    "                df = self.balanced_sample()\n",
    "                df = pd.concat([uf.drop_static_cols(df[df[self.yvar] == 1], yvar=self.yvar),\n",
    "                                uf.drop_static_cols(df[df[self.yvar] == 0], yvar=self.yvar)])\n",
    "                y_samp, X_samp = patsy.dmatrices(self.formula, data=df, return_type='dataframe')\n",
    "                X_samp.drop(self.yvar, axis=1, errors='ignore', inplace=True)\n",
    "\n",
    "                glm = GLM(y_samp, X_samp, family=sm.families.Binomial())\n",
    "                try:\n",
    "                    res = glm.fit()\n",
    "                    self.model_accuracy.append(self._scores_to_accuracy(res, X_samp, y_samp))\n",
    "                    self.models.append(res)\n",
    "                    i += 1\n",
    "                except Exception as e:\n",
    "                    errors += 1 # to avoid infinite loop for misspecified matrix\n",
    "                    print('Error: {}'.format(e))\n",
    "\n",
    "            print(\"\\nAverage Accuracy:\", \"{}%\".\n",
    "                  format(round(np.mean(self.model_accuracy) * 100, 2)))\n",
    "            print(errors)\n",
    "        else:\n",
    "            # ignore any imbalance and fit one model\n",
    "            print('Fitting 1 (Unbalanced) Model...')\n",
    "            glm = GLM(self.y, self.X, family=sm.families.Binomial())\n",
    "            res = glm.fit()\n",
    "            self.model_accuracy=pd.concat([self.model_accuracy,self._scores_to_accuracy(res, self.X, self.y)])\n",
    "            self.models=pd.concat([self.models,res])\n",
    "            print(\"\\nAccuracy\", round(np.mean(self.model_accuracy[0]) * 100, 2))\n",
    "            \n",
    "            \n",
    "    def predict_scores(self):\n",
    "        \"\"\"\n",
    "        Predict Propensity scores for each observation.\n",
    "        Adds a \"scores\" columns to self.data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        scores = np.zeros(len(self.X))\n",
    "        for i in range(self.nmodels):\n",
    "            m = self.models[i]\n",
    "            scores += m.predict(self.X[m.params.index])\n",
    "        self.data['scores'] = scores/self.nmodels\n",
    "\n",
    "    def match(self, threshold=0.001, nmatches=1, method='min', max_rand=10):\n",
    "        \"\"\"\n",
    "        Finds suitable match(es) for each record in the minority\n",
    "        dataset, if one exists. Records are exlcuded from the final\n",
    "        matched dataset if there are no suitable matches.\n",
    "\n",
    "        self.matched_data contains the matched dataset once this\n",
    "        method is called\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        threshold : float\n",
    "            threshold for fuzzy matching matching\n",
    "            i.e. |score_x - score_y| >= theshold\n",
    "        nmatches : int\n",
    "            How majority profiles should be matched\n",
    "            (at most) to minority profiles\n",
    "        method : str\n",
    "            Strategy for when multiple majority profiles\n",
    "            are suitable matches for a single minority profile\n",
    "            \"random\" - choose randomly (fast, good for testing)\n",
    "            \"min\" - choose the profile with the closest score\n",
    "        max_rand : int\n",
    "            max number of profiles to consider when using random tie-breaks\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if 'scores' not in self.data.columns:\n",
    "            print(\"Propensity Scores have not been calculated. Using defaults...\")\n",
    "            self.fit_scores()\n",
    "            self.predict_scores()\n",
    "        test_scores = self.data[self.data[self.yvar]==True][['scores']]\n",
    "        ctrl_scores = self.data[self.data[self.yvar]==False][['scores']]\n",
    "        result, match_ids = [], []\n",
    "        for i in range(len(test_scores)):\n",
    "            # uf.progress(i+1, len(test_scores), 'Matching Control to Test...')\n",
    "            match_id = i\n",
    "            score = test_scores.iloc[i]\n",
    "            if method == 'random':\n",
    "                bool_match = abs(ctrl_scores - score) <= threshold\n",
    "                matches = ctrl_scores.loc[bool_match[bool_match.scores].index]\n",
    "            elif method == 'min':\n",
    "                matches = abs(ctrl_scores - score).sort_values('scores').head(nmatches)\n",
    "            else:\n",
    "                raise(AssertionError, \"Invalid method parameter, use ('random', 'min')\")\n",
    "            if len(matches) == 0:\n",
    "                continue\n",
    "            # randomly choose nmatches indices, if len(matches) > nmatches\n",
    "            select = nmatches if method != 'random' else np.random.choice(range(1, max_rand+1), 1)\n",
    "            chosen = np.random.choice(matches.index, min(select, nmatches), replace=True)\n",
    "            result.extend([test_scores.index[i]] + list(chosen))\n",
    "            match_ids.extend([i] * (len(chosen)+1))\n",
    "        self.matched_data = self.data.loc[result]\n",
    "        self.matched_data['match_id'] = match_ids\n",
    "        self.matched_data['record_id'] = self.matched_data.index\n",
    "\n",
    "    def select_from_design(self, cols):\n",
    "        d = pd.DataFrame()\n",
    "        for c in cols:\n",
    "            d = pd.concat([d, self.X.select(lambda x: x.startswith(c), axis=1)], axis=1)\n",
    "        return d\n",
    "\n",
    "    def balanced_sample(self, data=None):\n",
    "        if not data:\n",
    "            data=self.data\n",
    "        minor, major = data[data[self.yvar] == self.minority], data[data[self.yvar] == self.majority]\n",
    "        return pd.concat([major.sample(len(minor)),minor]).dropna()\n",
    "\n",
    "    def plot_scores(self):\n",
    "        \"\"\"\n",
    "        Plots the distribution of propensity scores before matching between\n",
    "        our test and control groups\n",
    "        \"\"\"\n",
    "        assert 'scores' in self.data.columns, \"Propensity scores haven't been calculated, use Matcher.predict_scores()\"\n",
    "        sns.distplot(self.data[self.data[self.yvar]==0].scores, label='Control')\n",
    "        sns.distplot(self.data[self.data[self.yvar]==1].scores, label='Test')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xlim((0, 1))\n",
    "        plt.title(\"Propensity Scores Before Matching\")\n",
    "        plt.ylabel(\"Percentage (%)\")\n",
    "        plt.xlabel(\"Scores\")\n",
    "\n",
    "    def prop_test(self, col):\n",
    "        \"\"\"\n",
    "        Performs a Chi-Square test of independence on <col>\n",
    "        See stats.chi2_contingency()\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        col : str\n",
    "            Name of column on which the test should be performed\n",
    "\n",
    "        Returns\n",
    "        ______\n",
    "        dict\n",
    "            {'var': <col>,\n",
    "             'before': <pvalue before matching>,\n",
    "             'after': <pvalue after matching>}\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        if not uf.is_continuous(col, self.X) and col not in self.exclude:\n",
    "            pval_before = round(stats.chi2_contingency(self.prep_prop_test(self.data, col))[1], 6)\n",
    "            pval_after = round(stats.chi2_contingency(self.prep_prop_test(self.matched_data, col))[1], 6)\n",
    "            return {'var':col, 'before':pval_before, 'after':pval_after}\n",
    "        else:\n",
    "            print(\"{} is a continuous variable\".format(col))\n",
    "\n",
    "   \n",
    "    def compare_continuous(self, save=False, return_table=False):\n",
    "        \"\"\"\n",
    "        Plots the ECDFs for continuous features before and\n",
    "        after matching. Each chart title contains test results\n",
    "        and statistics to summarize how similar the two distributions\n",
    "        are (we want them to be close after matching).\n",
    "\n",
    "        Tests performed:\n",
    "        Kolmogorov-Smirnov Goodness of fit Test (KS-test)\n",
    "            This test statistic is calculated on 1000\n",
    "            permuted samples of the data, generating\n",
    "            an imperical p-value.  See pymatch.functions.ks_boot()\n",
    "            This is an adaptation of the ks.boot() method in\n",
    "            the R \"Matching\" package\n",
    "            https://www.rdocumentation.org/packages/Matching/versions/4.9-2/topics/ks.boot\n",
    "        Chi-Square Distance:\n",
    "            Similarly this distance metric is calculated on\n",
    "            1000 permuted samples.\n",
    "            See pymatch.functions.grouped_permutation_test()\n",
    "\n",
    "        Other included Stats:\n",
    "        Standarized mean and median differences\n",
    "        How many standard deviations away are the mean/median\n",
    "        between our groups before and after matching\n",
    "        i.e. abs(mean(control) - mean(test)) / std(control.union(test))\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        return_table : bool\n",
    "            Should the function a table with tests and statistics?\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame (optional)\n",
    "            Table of before/after statistics if return_table == True\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        test_results = []\n",
    "        for col in self.matched_data.columns:\n",
    "            if uf.is_continuous(col, self.X) and col not in self.exclude:\n",
    "                # organize data\n",
    "                trb, cob = self.test[col], self.control[col]\n",
    "                tra = self.matched_data[self.matched_data[self.yvar]==True][col]\n",
    "                coa = self.matched_data[self.matched_data[self.yvar]==False][col]\n",
    "                xtb, xcb = ECDF(trb), ECDF(cob)\n",
    "                xta, xca = ECDF(tra),ECDF(coa)\n",
    "\n",
    "                # before/after stats\n",
    "                std_diff_med_before, std_diff_mean_before = uf.std_diff(trb, cob)\n",
    "                std_diff_med_after, std_diff_mean_after = uf.std_diff(tra, coa)\n",
    "                pb, truthb = uf.grouped_permutation_test(uf.chi2_distance, trb, cob)\n",
    "                pa, trutha = uf.grouped_permutation_test(uf.chi2_distance, tra, coa)\n",
    "                ksb = round(uf.ks_boot(trb, cob, nboots=1000), 6)\n",
    "                ksa = round(uf.ks_boot(tra, coa, nboots=1000), 6)\n",
    "\n",
    "                # plotting\n",
    "                f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True, figsize=(12, 5))\n",
    "                ax1.plot(xcb.x, xcb.y, label='Control', color=self.control_color)\n",
    "                ax1.plot(xtb.x, xtb.y, label='Case', color=self.test_color)\n",
    "                ax1.plot(xcb.x, xcb.y, label='Control', color=self.control_color)\n",
    "                ax1.plot(xtb.x, xtb.y, label='Case', color=self.test_color)\n",
    "\n",
    "                title_str = '''\n",
    "                ECDF for {} {} Matching\n",
    "                KS p-value: {}\n",
    "                Grouped Perm p-value: {}\n",
    "                Std. Median Difference: {}\n",
    "                Std. Mean Difference: {}\n",
    "                '''\n",
    "                ax1.set_title(title_str\\\n",
    "                  .format(col, \"before\", ksb, pb, std_diff_med_before, std_diff_mean_before))\n",
    "                ax2.plot(xca.x, xca.y, label='Control')\n",
    "                ax2.plot(xta.x, xta.y, label='Test')\n",
    "                ax2.set_title(title_str\\\n",
    "                  .format(col, \"after\", ksa, pa, std_diff_med_after, std_diff_mean_after))\n",
    "                ax2.legend(loc=\"lower right\")\n",
    "                plt.xlim((0, np.percentile(xta.x, 99)))\n",
    "\n",
    "                test_results=pd.concat([test_results,{\n",
    "                        \"var\": col,\n",
    "                        \"ks_before\": ksb,\n",
    "                        \"ks_after\": ksa,\n",
    "                        \"grouped_chisqr_before\": pb,\n",
    "                        \"grouped_chisqr_after\": pa,\n",
    "                        \"std_median_diff_before\": std_diff_med_before,\n",
    "                        \"std_median_diff_after\": std_diff_med_after,\n",
    "                        \"std_mean_diff_before\": std_diff_mean_before,\n",
    "                        \"std_mean_diff_after\": std_diff_mean_after\n",
    "                    }])\n",
    "\n",
    "        var_order = [\n",
    "                    \"var\",\n",
    "                    \"ks_before\",\n",
    "                    \"ks_after\",\n",
    "                    \"grouped_chisqr_before\",\n",
    "                    \"grouped_chisqr_after\",\n",
    "                    \"std_median_diff_before\",\n",
    "                    \"std_median_diff_after\",\n",
    "                    \"std_mean_diff_before\",\n",
    "                    \"std_mean_diff_after\"\n",
    "                ]\n",
    "\n",
    "        return pd.DataFrame(test_results)[var_order] if return_table else None\n",
    "\n",
    "    def compare_categorical(self, return_table=False):\n",
    "        \"\"\"\n",
    "        Plots the proportional differences of each enumerated\n",
    "        discete column for test and control.\n",
    "        i.e. <prop_test_that_have_x>  - <prop_control_that_have_x>\n",
    "        Each chart title contains the results from a\n",
    "        Chi-Square Test of Independence before and after\n",
    "        matching.\n",
    "        See pymatch.prop_test()\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        return_table : bool\n",
    "            Should the function return a table with\n",
    "            test results?\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        pd.DataFrame() (optional)\n",
    "            Table with the p-values of the Chi-Square contingency test\n",
    "            for each discrete column before and after matching\n",
    "\n",
    "        \"\"\"\n",
    "        def prep_plot(data, var, colname):\n",
    "            t, c = data[data[self.yvar] == 1], data[data[self.yvar] == 0]\n",
    "            # dummy var for counting\n",
    "            dummy = [i for i in t.columns if i not in \\\n",
    "                      (var, \"match_id\", \"record_id\", \"weight\")][0]\n",
    "            countt = t[[var, dummy]].groupby(var).count() / len(t)\n",
    "            countc = c[[var, dummy]].groupby(var).count() / len(c)\n",
    "            ret = (countt-countc).dropna()\n",
    "            ret.columns = [colname]\n",
    "            return ret\n",
    "\n",
    "        title_str = '''\n",
    "        Proportional Difference (test-control) for {} Before and After Matching\n",
    "        Chi-Square Test for Independence p-value before | after:\n",
    "        {} | {}\n",
    "        '''\n",
    "        test_results = []\n",
    "        for col in self.matched_data.columns:\n",
    "            if not uf.is_continuous(col, self.X) and col not in self.exclude:\n",
    "                dbefore = prep_plot(self.data, col, colname=\"before\")\n",
    "                dafter = prep_plot(self.matched_data, col, colname=\"after\")\n",
    "                df = dbefore.join(dafter)\n",
    "                test_results_i = self.prop_test(col)\n",
    "                test_results=pd.concat([test_results,test_results_i])\n",
    "\n",
    "                # plotting\n",
    "                df.plot.bar(alpha=.8)\n",
    "                plt.title(title_str.format(col, test_results_i[\"before\"], test_results_i[\"after\"]))\n",
    "                lim = max(.09, abs(df).max().max()) + .01\n",
    "                plt.ylim((-lim, lim))\n",
    "        return pd.DataFrame(test_results)[['var', 'before', 'after']] if return_table else None\n",
    "\n",
    "      \n",
    "    def prep_prop_test(self, data, var):\n",
    "        \"\"\"\n",
    "        Helper method for running chi-square contingency tests\n",
    "\n",
    "        Balances the counts of discrete variables with our groups\n",
    "        so that missing levels are replaced with 0.\n",
    "        i.e. if the test group has no records with x as a field\n",
    "        for a given column, make sure the count for x is 0\n",
    "        and not missing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame()\n",
    "            Data to use for counting\n",
    "        var : str\n",
    "            Column to use within data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A table (list of lists) of counts for all enumerated field within <var>\n",
    "            for test and control groups.\n",
    "        \"\"\"\n",
    "        counts = data.groupby([var, self.yvar]).count().reset_index()\n",
    "        table = []\n",
    "        for t in (0, 1):\n",
    "            os_counts = counts[counts[self.yvar] ==t]\\\n",
    "                                     .sort_values(var)\n",
    "            cdict = {}\n",
    "            for row in os_counts.iterrows():\n",
    "                row = row[1]\n",
    "                cdict[row[var]] = row[2]\n",
    "            table=pd.concat([table,cdict])\n",
    "        # fill empty keys as 0\n",
    "        all_keys = set(chain.from_iterable(table))\n",
    "        for d in table:\n",
    "            d.update((k, 0) for k in all_keys if k not in d)\n",
    "        ctable = [[i[k] for k in sorted(all_keys)] for i in table]\n",
    "        return ctable\n",
    "\n",
    "    def prop_retained(self):\n",
    "        \"\"\"\n",
    "        Returns the proportion of data retained after matching\n",
    "        \"\"\"\n",
    "        return len(self.matched_data[self.matched_data[self.yvar] == self.minority]) * 1.0 / \\\n",
    "               len(self.data[self.data[self.yvar] == self.minority])\n",
    "\n",
    "    def tune_threshold(self, method, nmatches=1, rng=np.arange(0, .001, .0001)):\n",
    "        \"\"\"\n",
    "        Matches data over a grid to optimize threshold value and plots results.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        method : str\n",
    "            Method used for matching (use \"random\" for this method)\n",
    "        nmatches : int\n",
    "            Max number of matches per record. See pymatch.match()\n",
    "        rng: : list / np.array()\n",
    "            Grid of threshold values\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for i in rng:\n",
    "            self.match(method=method, nmatches=nmatches, threshold=i)\n",
    "            results=pd.concat([results,self.prop_retained()])\n",
    "        plt.plot(rng, results)\n",
    "        plt.title(\"Proportion of Data retained for grid of threshold values\")\n",
    "        plt.ylabel(\"Proportion Retained\")\n",
    "        plt.xlabel(\"Threshold\")\n",
    "        plt.xticks(rng)\n",
    "\n",
    "    def record_frequency(self):\n",
    "        \"\"\"\n",
    "        Calculates the frequency of specifi records in\n",
    "        the matched dataset\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame()\n",
    "            Frequency table of the number records\n",
    "            matched once, twice, ..., etc.\n",
    "        \"\"\"\n",
    "        freqs = self.matched_data.groupby(\"record_id\")\\\n",
    "                    .count().groupby(\"match_id\").count()\\\n",
    "                    [[\"scores\"]].reset_index()\n",
    "        freqs.columns = [\"freq\", \"n_records\"]\n",
    "        return freqs\n",
    "\n",
    "    def assign_weight_vector(self):\n",
    "        record_freqs = self.matched_data.groupby(\"record_id\")\\\n",
    "                           .count()[['match_id']].reset_index()\n",
    "        record_freqs.columns = [\"record_id\", \"weight\"]\n",
    "        fm = record_freqs.merge(self.matched_data, on=\"record_id\")\n",
    "        fm['weight'] = 1/fm['weight']\n",
    "        self.matched_data = fm\n",
    "\n",
    "    @staticmethod\n",
    "    def _scores_to_accuracy(m, X, y):\n",
    "        preds = [1.0 if i >= .5 else 0.0 for i in m.predict(X)]\n",
    "        return (y.to_numpy().T == preds).sum() * 1.0 / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_demog=Matcher(celiac_df, controls_df, yvar='label', exclude=['person_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "m_demog.fit_scores(balance=True, nmodels=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_demog.predict_scores()\n",
    "m_demog.plot_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cat = ['race', 'ethnicity', 'sex_at_birth','age']\n",
    "col_patid = m_cat + ['person_id', 'label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "max_matches=math.ceil(len(controls_df)/len(celiac_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "pval_iter={}\n",
    "for i in tqdm(range(2,max_matches,1)):\n",
    "    m_demog.match(method=\"random\", nmatches=i, threshold=0.0001)\n",
    "    dat_matched=m_demog.matched_data.sort_values(\"match_id\")\n",
    "    mat=dat_matched.loc[:,col_patid][~dat_matched.loc[:,col_patid].duplicated()]\n",
    "    # if len(mat)!=len(dat_matched):\n",
    "        # print(i)\n",
    "        # print(len(mat))\n",
    "        # print(len(dat_matched))\n",
    "    pval_iter[i]={}\n",
    "    for r in m_cat:\n",
    "        pval_iter[i][r]=[]\n",
    "        if 'PC' in r:\n",
    "            celiac=mat[mat['label']==1]\n",
    "            controls=mat[mat['label']==0]\n",
    "            pval_iter[i][r]=stats.ttest_ind(celiac[r],controls[r]).pvalue\n",
    "        else:\n",
    "            if r!='label':\n",
    "                obs=pd.crosstab(mat[r], mat['label'])\n",
    "                g, p, dof, expctd = chi2_contingency(obs)\n",
    "                pval_iter[i][r]=p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=pd.DataFrame.from_dict(pval_iter, orient='index')\n",
    "plt.plot(res.T,'.');\n",
    "plt.plot([0,4],[0.01,0.01],'r--')\n",
    "plt.title(' propensity scores by covariate in simulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celiac_df#[~pd.isna(celiac_df['PC1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_demog.match(method=\"random\", nmatches=max_matches, threshold=0.0001)\n",
    "dat_matched=m_demog.matched_data.sort_values(\"match_id\")\n",
    "mat=dat_matched.loc[:,col_patid][~dat_matched.loc[:,col_patid].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celiac = mat[mat['label']==1]\n",
    "controls = mat[mat['label']==0]\n",
    "print(len(celiac))\n",
    "print(len(controls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celiac.reset_index(drop = True,inplace=True)\n",
    "controls.reset_index(drop = True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_demog=Matcher(celiac, controls, yvar='label', exclude=['person_id'])\n",
    "np.random.seed(123456)\n",
    "m_demog.fit_scores(balance=True, nmodels=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_demog.predict_scores()\n",
    "m_demog.plot_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3)) \n",
    "# Creating plot\n",
    "plt.boxplot([np.array(celiac.age), np.array(controls.age)])\n",
    "plt.xticks([1, 2], ['celiac', 'controls'], fontsize = 15)\n",
    "plt.title('post-match age dist')\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data = pd.concat([celiac,controls])\n",
    "#match_data['pat_id']=match_data['person_id'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make demographic file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = os.getenv(\"WORKSPACE_BUCKET\")\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data.to_csv('celiac_matched_data_non_genetic.tsv', index=False, sep='\\t')\n",
    "\n",
    "!gsutil cp 'celiac_matched_data_non_genetic.tsv' {bucket}/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data.to_csv('celiac_matched_data_non_genetic.csv', index=False)\n",
    "\n",
    "!gsutil cp 'celiac_matched_data_non_genetic.csv' {bucket}/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data = pd.read_csv('celiac_matched_data_non_genetic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics =pd.get_dummies(match_data[['race','ethnicity','sex_at_birth']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics['age'] = match_data['age']\n",
    "demographics['label'] = match_data['label']\n",
    "demographics['person_id'] = match_data['person_id']\n",
    "demographics.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save phenotypes locally\n",
    "phenotypes = (demographics[[\"person_id\" , \"label\",\"race_Asian\", \"race_Black or African American\",\"race_White\",\n",
    "                            \"race_Native Hawaiian or Other Pacific Islander\",\"race_Middle Eastern or North African\"\n",
    "                            ,\"sex_at_birth_Female\",'sex_at_birth_Male','sex_at_birth_Intersex',\n",
    "                            \"ethnicity_Hispanic or Latino\", \"sex_at_birth_Male\", \"age\"]]\n",
    "              .rename(columns={'ethnicity_Hispanic or Latino': 'is_hispanic',\n",
    "                              'sex_at_birth_Male': 'is_male',\n",
    "                              'race_Asian': 'is_asian',\n",
    "                              'race_White': 'is_white',\n",
    "                              'race_Native Hawaiian or Other Pacific Islander': 'is_Pacific_islander',\n",
    "                              'race_Middle Eastern or North African': 'is_MENA',\n",
    "                              'sex_at_birth_Female': 'is_female',\n",
    "                              'sex_at_birth_Intersex': 'is_intersex',\n",
    "                              'race_Black or African American': 'is_black'})\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['is_hispanic','is_male','is_female','is_intersex','is_asian', 'is_white','is_black','is_MENA','is_Pacific_islander']:\n",
    "    phenotypes[col] = phenotypes[col].astype(int)\n",
    "phenotypes[\"person_id\"] = phenotypes[\"person_id\"].astype(str)\n",
    "phenotypes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes.to_csv('celiac_demo_non_genetic.tsv', index=False, sep='\\t')\n",
    "\n",
    "!gsutil cp 'celiac_demo_non_genetic.tsv' {bucket}/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
