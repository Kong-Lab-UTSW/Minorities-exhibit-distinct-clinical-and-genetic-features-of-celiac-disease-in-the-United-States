{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274eaa9d-a93f-434d-9a8e-a9b9b9a4df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c699bb8-2084-498c-b3d8-cf78462557d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path2 = '20240612_HLA2.csv'\n",
    "HLA = pd.read_csv(file_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46545e",
   "metadata": {},
   "source": [
    "## Chi Square for updated HLA types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc34e42-af1a-48a1-9b83-ad39929c8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "file_path2 = '20240612_HLA2.csv'\n",
    "HLA = pd.read_csv(file_path2)\n",
    "\n",
    "# Assuming your DataFrame is already loaded into `HLA`\n",
    "# Correct the mapping of 'CeD' to be binary\n",
    "HLA['CeD'] = HLA['CeD'].map({2: 0, 1: 1})\n",
    "\n",
    "# Create a contingency table with frequencies\n",
    "contingency_table = pd.crosstab(HLA['DQ_geno_4'], HLA['CeD'])\n",
    "\n",
    "# Calculate percentages within each CeD group (column-wise percentages)\n",
    "percentage_table = contingency_table.div(contingency_table.sum(axis=0), axis=1) * 100\n",
    "\n",
    "# Format the contingency table to \"count (percentage%)\"\n",
    "formatted_table = contingency_table.astype(str) + \" (\" + percentage_table.round(2).astype(str) + \"%)\"\n",
    "\n",
    "# Initialize an empty DataFrame for results\n",
    "results = pd.DataFrame(columns=[\"Genotype\", \"Odds Ratio\", \"P-value\"])\n",
    "for category in contingency_table.index:\n",
    "    # Create the 2x2 table for each category\n",
    "    c_table = contingency_table.loc[[category]]\n",
    "    if c_table.shape[1] < 2:  # Ensures there are two columns\n",
    "        c_table = pd.concat([c_table, pd.DataFrame([[0, 0]], columns=c_table.columns)], ignore_index=True)\n",
    "    complement = pd.DataFrame(contingency_table.drop(category).sum()).T\n",
    "    if complement.shape[1] < 2:\n",
    "        complement = pd.concat([complement, pd.DataFrame([[0, 0]], columns=complement.columns)], ignore_index=True)\n",
    "    full_table = pd.concat([c_table, complement], ignore_index=True)\n",
    "\n",
    "    # Calculate Chi-square test\n",
    "    chi2, p, dof, expected = chi2_contingency(full_table)\n",
    "\n",
    "    # Calculate Odds Ratio\n",
    "    if full_table.iloc[0, 0] != 0 and full_table.iloc[1, 1] != 0:\n",
    "        OR = (full_table.iloc[0, 0] / full_table.iloc[1, 0]) / (full_table.iloc[0, 1] / full_table.iloc[1, 1])\n",
    "        OR = f\"{OR:.2f}\"\n",
    "    else:\n",
    "        OR = \"Not calculable\"\n",
    "\n",
    "    # Construct new row for results DataFrame\n",
    "    new_row = pd.DataFrame([[category, OR, f\"{p:.2e}\"]], columns=[\"Genotype\", \"Odds Ratio\", \"P-value\"])\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "# Print formatted tables\n",
    "print(\"Formatted Contingency Table:\")\n",
    "print(formatted_table)\n",
    "print(\"\\nAnalysis Results:\")\n",
    "print(results)\n",
    "\n",
    "# Export to CSV\n",
    "formatted_table.to_csv(\"Formatted_Contingency_Table.csv\")\n",
    "results.to_csv(\"Analysis_Results.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6609de",
   "metadata": {},
   "source": [
    "## DQ genotypes by inclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98efea-7f2a-44a2-a095-8529408ad6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype']=42\n",
    "\n",
    "# Group by 'diagnosis domain' and 'DQ_geno', then count the occurrences\n",
    "geno_counts = HLA.groupby(['diagnosis domain', 'DQ_geno_4']).size().unstack(fill_value=0)\n",
    "\n",
    "# Normalize the counts to get percentages\n",
    "geno_percentages = geno_counts.div(geno_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "geno_percentages.plot(kind='bar', stacked=True, ax=ax, colormap='tab20')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_xlabel('Diagnosis Domain')\n",
    "ax.set_title('Distribution of DQ_geno Across Diagnosis Domains')\n",
    "ax.legend(['2.5/2.5','2.5/2.2','2.5/7.5','2.5/8.1','2.5/X','2.2/7.5','2.2/2.2','2.2/8.1', '2.2/X', '7.5/7.5', '7.5/8.1', '7.5/X','8.1/8.1',\n",
    "       '8.1/X', 'X/X'] , bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Improve layout to accommodate legend\n",
    "plt.tight_layout()\n",
    "plt.savefig('S.Figure 8.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f9cd63",
   "metadata": {},
   "source": [
    "## DQ genotype by ancestry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba5129-8cbb-4d3e-bb51-c5937898d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Load the dataset\n",
    "file_path2 = '20240612_HLA.csv'\n",
    "HLA = pd.read_csv(file_path2)\n",
    "\n",
    "# Define significant genotypes\n",
    "significant_genotypes = ['2.2/7.5', '2.5/2.2', '2.5/2.5', '2.5/7.5', '2.5/8.1', '2.5/X']\n",
    "\n",
    "# Map CeD values to statuses\n",
    "HLA['CeD_Status'] = HLA['CeD'].map({1: 'Control', 2: 'Case'})\n",
    "\n",
    "# Update ancestries 'sas', 'mid', 'eas' to 'Other'\n",
    "HLA['ancestry_pred'] = HLA['ancestry_pred'].replace(['sas', 'mid', 'eas'], 'Other')\n",
    "\n",
    "# Create dummies for all genotypes\n",
    "dummies = pd.get_dummies(HLA['DQ_geno_4'])\n",
    "HLA = pd.concat([HLA, dummies], axis=1)\n",
    "\n",
    "# Group by 'ancestry_pred', 'CeD_Status' and sum occurrences for each genotype\n",
    "geno_counts = HLA.groupby(['ancestry_pred', 'CeD_Status'])[dummies.columns].sum()\n",
    "\n",
    "# Normalize the counts to get percentages\n",
    "geno_percentages = geno_counts.div(geno_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Define a distinct color map for all genotypes\n",
    "all_colors = plt.get_cmap('tab20')(np.linspace(0, 1, len(dummies.columns)))\n",
    "color_map = {geno: all_colors[i % len(all_colors)] for i, geno in enumerate(dummies.columns)}\n",
    "\n",
    "# Set a specific color for X/X genotype\n",
    "color_map['X/X'] = 'yellow'  # Assign yellow color specifically for the X/X genotype\n",
    "\n",
    "# Setting the font globally\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "# Define odds ratios for sorting\n",
    "odds_ratios = {\n",
    "    '2.2/2.2': 0.50, '2.2/7.5': 2.14, '2.2/8.1': 1.21, '2.2/X': 0.66,\n",
    "    '2.5/2.2': 3.62, '2.5/2.5': 4.34, '2.5/7.5': 1.47, '2.5/8.1': 2.06,\n",
    "    '2.5/X': 2.16, '7.5/7.5': 0.20, '7.5/8.1': 0.54, '7.5/X': 0.61,\n",
    "    '8.1/8.1': 1.48, '8.1/X': 0.88, 'X/X': 0.46\n",
    "}\n",
    "\n",
    "# Sort columns of case_data by odds ratios in descending order\n",
    "case_data = geno_percentages.xs('Case', level='CeD_Status')\n",
    "sorted_columns = sorted(case_data.columns, key=lambda x: odds_ratios.get(x, 0), reverse=True)\n",
    "case_data = case_data[sorted_columns]\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "case_data.plot(kind='barh', stacked=True, ax=ax, color=[color_map[col] for col in case_data.columns])\n",
    "ax.set_title('HLA-DQ Distribution Across Genetic Ancestries')\n",
    "ax.set_xlabel('Percentage')\n",
    "ax.set_ylabel('Ancestry and Genotype')\n",
    "ax.legend(title='HLA-DQ', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('geno_distribution_cases.pdf')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
