{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6323da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0748bf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path2 = 'HLA_concordance_cleaned2.csv'\n",
    "HLA_concordance = pd.read_csv(file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_combinations(row):\n",
    "    # Initialize the new columns\n",
    "    row['hibag_DQ2.5'], row['hibag_DQ2.2'], row['hibag_DQ7.5'], row['hibag_DQ8.1'] = 'negative', 'negative', 'negative', 'negative'\n",
    "    \n",
    "    # Condition for hibag_DQ2.5\n",
    "    if '5:01:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']] and '2:01:00' in [row['hibag.DQB1.1'], row['hibag.DQB1.2']]:\n",
    "        row['hibag_DQ2.5'] = 'positive'\n",
    "        \n",
    "    # Condition for hibag_DQ2.2\n",
    "    if '2:02:00' in [row['hibag.DQB1.1'], row['hibag.DQB1.2']] and ('3:01:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']] or '2:01:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']]):\n",
    "        row['hibag_DQ2.2'] = 'positive'\n",
    "\n",
    "    # Condition for hibag_DQ7.5\n",
    "    if ('5:01:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']] or '5:05:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']]) and '3:01:00' in [row['hibag.DQB1.1'], row['hibag.DQB1.2']]:\n",
    "        row['hibag_DQ7.5'] = 'positive'\n",
    "\n",
    "    # Condition for hibag_DQ8.1\n",
    "    if (('3:01:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']] or '3:03:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']]) and '3:02:00' in [row['hibag.DQB1.1'], row['hibag.DQB1.2']]):\n",
    "        row['hibag_DQ8.1'] = 'positive'\n",
    "    \n",
    "    # Combining genotype risks into a single column\n",
    "    genotypes = []\n",
    "    if row['hibag_DQ2.5'] == 'positive':\n",
    "        genotypes.append('2.5')\n",
    "    if row['hibag_DQ2.2'] == 'positive':\n",
    "        genotypes.append('2.2')\n",
    "    if row['hibag_DQ7.5'] == 'positive':\n",
    "        genotypes.append('7.5')\n",
    "    if row['hibag_DQ8.1'] == 'positive':\n",
    "        genotypes.append('8.1')\n",
    "    \n",
    "    row['hibag_genotype'] = '/'.join(genotypes) if genotypes else 'X'\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051fa4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_combinations_hla(row):\n",
    "    # Initialize the new columns\n",
    "    row['hla_la_DQ2.5'], row['hla_la_DQ2.2'], row['hla_la_DQ7.5'], row['hla_la_DQ8.1'] = 'negative', 'negative', 'negative', 'negative'\n",
    "    \n",
    "    # Condition for hla_la_DQ2.5\n",
    "    if '5:01:00' in [row['hla.la.DQA1.1'], row['hla.la.DQA1.2']] and '2:01:00' in [row['hla.la.DQB1.1'], row['hla.la.DQB1.2']]:\n",
    "        row['hla_la_DQ2.5'] = 'positive'\n",
    "        \n",
    "    # Condition for hla_la_DQ2.2\n",
    "    if '2:01:00' in [row['hla.la.DQB1.1'], row['hla.la.DQB1.2']] and '2:01:00' in [row['hla.la.DQA1.1'], row['hla.la.DQA1.2']]:\n",
    "        row['hla_la_DQ2.2'] = 'positive'\n",
    "\n",
    "    # Condition for hla_la_DQ7.5\n",
    "    if ('5:01:00' in [row['hla.la.DQA1.1'], row['hla.la.DQA1.2']] or '5:05:00' in [row['hla.la.DQA1.1'], row['hla.la.DQA1.2']]) and '3:01:00' in [row['hla.la.DQB1.1'], row['hla.la.DQB1.2']]:\n",
    "        row['hla_la_DQ7.5'] = 'positive'\n",
    "\n",
    "    # Condition for hla_la_DQ8.1\n",
    "    if (('3:01:00' in [row['hla.la.DQA1.1'], row['hla.la.DQA1.2']] or '3:03:00' in [row['hla.la.DQA1.1'], row['hla.la.DQA1.2']]) and '3:02:00' in [row['hla.la.DQB1.1'], row['hla.la.DQB1.2']]):\n",
    "        row['hla_la_DQ8.1'] = 'positive'\n",
    "    \n",
    "    # Combining genotype risks into a single column\n",
    "    genotypes = []\n",
    "    if row['hla_la_DQ2.5'] == 'positive':\n",
    "        genotypes.append('2.5')\n",
    "    if row['hla_la_DQ2.2'] == 'positive':\n",
    "        genotypes.append('2.2')\n",
    "    if row['hla_la_DQ7.5'] == 'positive':\n",
    "        genotypes.append('7.5')\n",
    "    if row['hla_la_DQ8.1'] == 'positive':\n",
    "        genotypes.append('8.1')\n",
    "    \n",
    "    row['hla_la_genotype'] = '/'.join(genotypes) if genotypes else 'X'\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62887937",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_concordance1 = HLA_concordance.apply(check_combinations, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a7301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_concordance2 = HLA_concordance1.apply(check_combinations_hla, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf6c27",
   "metadata": {},
   "source": [
    "# HLA-LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_genotypes(row):\n",
    "    genotype_map = ['2.2', '2.5', '7.5', '8.1']\n",
    "    \n",
    "    for geno in genotype_map:\n",
    "        geno_x = f'{geno}/X'\n",
    "        geno_geno = f'{geno}/{geno}'\n",
    "\n",
    "        # Update hibag_genotype\n",
    "        if row['hibag_genotype'] == geno:\n",
    "            if row['DQ_geno_4'] == geno_x:\n",
    "                row['hibag_genotype'] = geno_x\n",
    "            elif row['DQ_geno_4'] == geno_geno:\n",
    "                row['hibag_genotype'] = geno_geno\n",
    "\n",
    "        # Update hla_la_genotype\n",
    "        if row['hla_la_genotype'] == geno:\n",
    "            if row['DQ_geno_prev'] == geno_x:\n",
    "                row['hla_la_genotype'] = geno_x\n",
    "            elif row['DQ_geno_prev'] == geno_geno:\n",
    "                row['hla_la_genotype'] = geno_geno\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc8ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_concordance4 = HLA_concordance2.apply(update_genotypes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd6c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_concordance4.to_csv('HLA_concordance3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##manual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f5121",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path3 = 'HLA_concordance3.csv'\n",
    "HLA_concordance5 = pd.read_csv(file_path3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1b9c3",
   "metadata": {},
   "source": [
    "## change tagSNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92f7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_concordance4['tag.genotype'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9757df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_dict = {\n",
    "    'X/X': 'X',\n",
    "    'DQ2.5/X': '2.5/X',\n",
    "    'DQ2.2/DQ7': '2.2/7.5',\n",
    "    'DQ2.2/X': '2.2/X',\n",
    "    'DQ2.5/DQ7': '2.5/7.5',\n",
    "    'DQ7/X': '7.5/X',\n",
    "    'DQ2.5/DQ8': '2.5/8.1',\n",
    "    'DQ7/DQ7': '7.5/7.5',\n",
    "    'DQ2.2/DQ8': '2.2/8.1',\n",
    "    'DQ8/X': '8.1/X',\n",
    "    'DQ2.5/DQ2.2': '2.5/2.2',\n",
    "    'DQ8/DQ8': '8.1/8.1',\n",
    "    'DQ2.5/DQ2.5': '2.5/2.5',\n",
    "    'DQ2.2/DQ2.2': '2.2/2.2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_concordance5['tag.genotype'] = HLA_concordance5['tag.genotype'].replace(replacement_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90678b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_concordance5.to_csv('HLA_concordance4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3221002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_concordance5['tag.genotype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df274833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Load the data\n",
    "file_path4 = 'HLA_concordance4.csv'\n",
    "HLA_concordance5 = pd.read_csv(file_path4)\n",
    "\n",
    "# Calculate concordance\n",
    "HLA_concordance5['concordant'] = (\n",
    "    (HLA_concordance5['tag.genotype'] == HLA_concordance5['hibag_genotype']) &\n",
    "    (HLA_concordance5['tag.genotype'] == HLA_concordance5['hla_la_genotype'])\n",
    ")\n",
    "\n",
    "# Calculate exclusive and shared overlaps\n",
    "only_tag = ((HLA_concordance5['tag.genotype'] != HLA_concordance5['hibag_genotype']) & \n",
    "            (HLA_concordance5['tag.genotype'] != HLA_concordance5['hla_la_genotype'])).sum()\n",
    "\n",
    "only_hibag = ((HLA_concordance5['hibag_genotype'] != HLA_concordance5['tag.genotype']) & \n",
    "              (HLA_concordance5['hibag_genotype'] != HLA_concordance5['hla_la_genotype'])).sum()\n",
    "\n",
    "only_hla_la = ((HLA_concordance5['hla_la_genotype'] != HLA_concordance5['tag.genotype']) & \n",
    "               (HLA_concordance5['hla_la_genotype'] != HLA_concordance5['hibag_genotype'])).sum()\n",
    "\n",
    "tag_and_hibag_only = ((HLA_concordance5['tag.genotype'] == HLA_concordance5['hibag_genotype']) & \n",
    "                      (HLA_concordance5['tag.genotype'] != HLA_concordance5['hla_la_genotype'])).sum()\n",
    "\n",
    "tag_and_hla_la_only = ((HLA_concordance5['tag.genotype'] == HLA_concordance5['hla_la_genotype']) & \n",
    "                       (HLA_concordance5['tag.genotype'] != HLA_concordance5['hibag_genotype'])).sum()\n",
    "\n",
    "hibag_and_hla_la_only = ((HLA_concordance5['hibag_genotype'] == HLA_concordance5['hla_la_genotype']) & \n",
    "                         (HLA_concordance5['hibag_genotype'] != HLA_concordance5['tag.genotype'])).sum()\n",
    "\n",
    "all_three = ((HLA_concordance5['tag.genotype'] == HLA_concordance5['hibag_genotype']) & \n",
    "             (HLA_concordance5['tag.genotype'] == HLA_concordance5['hla_la_genotype'])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4191bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Venn diagram\n",
    "plt.figure(figsize=(8, 8))\n",
    "venn3(\n",
    "    subsets=(\n",
    "        only_tag,\n",
    "        only_hibag,\n",
    "        tag_and_hibag_only,\n",
    "        only_hla_la,\n",
    "        tag_and_hla_la_only,\n",
    "        hibag_and_hla_la_only,\n",
    "        all_three\n",
    "    ),\n",
    "    set_labels=('Tag-SNP', 'HIBAG', 'HLA-LA')\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fdbf71",
   "metadata": {},
   "source": [
    "### count allele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa8b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "alleles_of_interest = ['2.2', '2.5', '7.5', '8.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5184632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Assume the data is already loaded into HLA_concordance5\n",
    "# HLA_concordance5 = pd.read_csv('HLA_concordance4.csv') # Example path\n",
    "\n",
    "# Define the alleles of interest\n",
    "alleles_of_interest = ['2.2', '2.5', '7.5', '8.1']\n",
    "\n",
    "# Function to get allele presence as a set for each column\n",
    "def get_allele_presence(df, allele):\n",
    "    tag_presence = df['tag.genotype'].apply(lambda x: allele in x.split('/'))\n",
    "    hibag_presence = df['hibag_genotype'].apply(lambda x: allele in x.split('/'))\n",
    "    hla_la_presence = df['hla_la_genotype'].apply(lambda x: allele in x.split('/'))\n",
    "    return tag_presence, hibag_presence, hla_la_presence\n",
    "\n",
    "# Set the font properties to Arial and size 16\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "# Create a 2x2 subplot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot Venn diagrams for each allele of interest\n",
    "for i, allele in enumerate(alleles_of_interest):\n",
    "    tag_presence, hibag_presence, hla_la_presence = get_allele_presence(HLA_concordance5, allele)\n",
    "    \n",
    "    # Calculate specific overlaps\n",
    "    only_tag = ((tag_presence) & (~hibag_presence) & (~hla_la_presence)).sum()\n",
    "    only_hibag = ((~tag_presence) & (hibag_presence) & (~hla_la_presence)).sum()\n",
    "    only_hla_la = ((~tag_presence) & (~hibag_presence) & (hla_la_presence)).sum()\n",
    "    tag_and_hibag_only = ((tag_presence) & (hibag_presence) & (~hla_la_presence)).sum()\n",
    "    tag_and_hla_la_only = ((tag_presence) & (~hibag_presence) & (hla_la_presence)).sum()\n",
    "    hibag_and_hla_la_only = ((~tag_presence) & (hibag_presence) & (hla_la_presence)).sum()\n",
    "    all_three = ((tag_presence) & (hibag_presence) & (hla_la_presence)).sum()\n",
    "    \n",
    "    # Plot Venn diagram\n",
    "    ax = axes[i]\n",
    "    venn = venn3(\n",
    "        subsets=(\n",
    "            only_tag,\n",
    "            only_hibag,\n",
    "            tag_and_hibag_only,\n",
    "            only_hla_la,\n",
    "            tag_and_hla_la_only,\n",
    "            hibag_and_hla_la_only,\n",
    "            all_three\n",
    "        ),\n",
    "        set_labels=('Tag-SNP', 'HIBAG', 'HLA-LA'),\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    # Adjust font sizes\n",
    "    for label in venn.set_labels:\n",
    "        label.set_fontsize(16)\n",
    "    for label in venn.subset_labels:\n",
    "        if label:\n",
    "            label.set_fontsize(16)\n",
    "\n",
    "# Adjust layout and remove titles\n",
    "plt.tight_layout()\n",
    "for ax in axes:\n",
    "    ax.set_title('')\n",
    "\n",
    "# Save the figure to a PDF\n",
    "output_pdf_path = 'allele_concordance_venn_diagrams.pdf'\n",
    "plt.savefig(output_pdf_path, format='pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
