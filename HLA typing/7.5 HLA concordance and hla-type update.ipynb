{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6b580-8a10-40d8-a679-ab3d1e1d7f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e89b74-7870-4c28-bbc6-bd6bfc74518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path2 = 'hla_la_hibag_tag_compare.csv'\n",
    "Sample_ID = pd.read_csv(file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f88b1-75c5-4d46-9524-7b142b87aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA = Sample_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002603a-2d0e-4cf0-8af8-3baf790f2043",
   "metadata": {},
   "source": [
    "# calclate the concordance of HLA typing using different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deea0026-7652-4acb-8192-1a20d040eaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "import matplotlib\n",
    "\n",
    "# Set the global font to Arial for all text in the figures\n",
    "matplotlib.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "def calculate_concordance(df, gene):\n",
    "    df_filtered = df.dropna(subset=[f'hibag.{gene}.1', f'hibag.{gene}.2', f'hla.la.{gene}.1', f'hla.la.{gene}.2'])\n",
    "    total_alleles = len(df_filtered) * 2  # Two alleles per sample\n",
    "    matched_alleles = 0\n",
    "\n",
    "    for _, row in df_filtered.iterrows():\n",
    "        hibag_alleles = [row[f'hibag.{gene}.1'], row[f'hibag.{gene}.2']]\n",
    "        hla_la_alleles = [row[f'hla.la.{gene}.1'], row[f'hla.la.{gene}.2']]\n",
    "\n",
    "        # Count matches for each allele and count each match twice for the double consideration\n",
    "        for ha in hibag_alleles:\n",
    "            if ha in hla_la_alleles:\n",
    "                matched_alleles += 1\n",
    "\n",
    "    # Calculate concordance rates based on matched alleles considering each allele separately\n",
    "    concordance_rate = matched_alleles / total_alleles if total_alleles > 0 else 0\n",
    "    return concordance_rate, len(df_filtered), matched_alleles\n",
    "\n",
    "# Assume 'HLA' is your DataFrame and it has been properly loaded\n",
    "genes = ['A', 'B', 'C', 'DPB1', 'DRB1', 'DQA1', 'DQB1']\n",
    "results = {gene: calculate_concordance(HLA, gene) for gene in genes}\n",
    "\n",
    "# Setup figure for subplots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(18, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each gene's Venn diagram\n",
    "for i, gene in enumerate(genes):\n",
    "    rate, samples, matches = results[gene]\n",
    "    v = venn2(subsets=(samples*2 - matches, samples*2 - matches, matches),\n",
    "              set_labels=(f'HiBAG {gene}', f'HLA-LA {gene}'),\n",
    "              ax=axes[i])\n",
    "    axes[i].text(0.5, 1.05, f'Total Matches: {matches}\\nRate: {rate:.2%}',\n",
    "                 ha='center', va='bottom', fontsize=16, transform=axes[i].transAxes)\n",
    "    axes[i].set_title(f'{gene} Concordance')\n",
    "\n",
    "# Hide unused axes if any\n",
    "for ax in axes[len(genes):]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('hla_concordance_venn_diagrams.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124364fe-3243-4496-9014-0960cbd5e9f8",
   "metadata": {},
   "source": [
    "# check HLA-DQA1 mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872bfac-f6d7-4b54-984d-c5229dec28bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'HLA' is your DataFrame and it has been properly loaded\n",
    "# Filter out rows where any of the DQA1 columns for both methods has NA, and explicitly create a copy to avoid setting with copy warnings\n",
    "alleles_filtered = HLA.dropna(subset=['hibag.DQA1.1', 'hibag.DQA1.2', 'hla.la.DQA1.1', 'hla.la.DQA1.2']).copy()\n",
    "\n",
    "def count_matched_alleles(row):\n",
    "    # Extract allele sets for HiBag and HLA-LA\n",
    "    hibag_set = {row['hibag.DQA1.1'], row['hibag.DQA1.2']}\n",
    "    hla_la_set = {row['hla.la.DQA1.1'], row['hla.la.DQA1.2']}\n",
    "    \n",
    "    # Calculate intersection to determine the number of matches\n",
    "    match_count = len(hibag_set.intersection(hla_la_set))\n",
    "    \n",
    "    # Return the number of matches (0, 1, 2)\n",
    "    return match_count\n",
    "\n",
    "# Apply the function to each row to determine the number of matching alleles\n",
    "alleles_filtered['Match Count'] = alleles_filtered.apply(count_matched_alleles, axis=1)\n",
    "\n",
    "# Export the updated DataFrame to a CSV file\n",
    "alleles_filtered.to_csv('alleles_matched_count.csv', index=False)\n",
    "print(\"Data with matched counts has been exported to 'alleles_matched_count.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61801fc9-68a6-4e4b-b31b-802a12e4cac9",
   "metadata": {},
   "source": [
    "# Check the frequent mistake that HIBAG might have based on mismatch is one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229fe807-a13c-4f33-add1-ee8a14cab802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'HLA' is your DataFrame and it has been properly loaded\n",
    "# Filter out rows where any of the DQA1 columns for both methods has NA, and explicitly create a copy to avoid setting with copy warnings\n",
    "alleles_filtered = HLA.dropna(subset=['hibag.DQA1.1', 'hibag.DQA1.2', 'hla.la.DQA1.1', 'hla.la.DQA1.2']).copy()\n",
    "\n",
    "def count_matched_alleles(row):\n",
    "    # Extract allele sets for HiBag and HLA-LA\n",
    "    hibag_set = {row['hibag.DQA1.1'], row['hibag.DQA1.2']}\n",
    "    hla_la_set = {row['hla.la.DQA1.1'], row['hla.la.DQA1.2']}\n",
    "    \n",
    "    # Calculate intersection to determine the number of matches\n",
    "    intersection = hibag_set.intersection(hla_la_set)\n",
    "    match_count = len(intersection)\n",
    "    \n",
    "    # Prepare data for mismatches when match_count is 1\n",
    "    mismatches_info = []\n",
    "    if match_count == 1:\n",
    "        matched_allele = intersection.pop()  # Remove the matched allele from consideration\n",
    "        remaining_hibag = hibag_set - {matched_allele}\n",
    "        remaining_hla_la = hla_la_set - {matched_allele}\n",
    "        \n",
    "        # Collect unmatched alleles with their corresponding unmatched set\n",
    "        for allele in remaining_hibag:\n",
    "            mismatches_info.append(f\"{allele} (Unmatched HLA-LA: {', '.join(remaining_hla_la)})\")\n",
    "\n",
    "    # Return the number of matches and the mismatched alleles info\n",
    "    return pd.Series([match_count, '; '.join(mismatches_info) if mismatches_info else ''])\n",
    "\n",
    "# Apply the function to each row to determine the number of matching alleles and collect mismatches\n",
    "alleles_filtered[['Match Count', 'Mismatch Info']] = alleles_filtered.apply(count_matched_alleles, axis=1)\n",
    "\n",
    "# Filter to get mismatches where Match Count is 1\n",
    "mismatches_info = alleles_filtered[alleles_filtered['Match Count'] == 1]['Mismatch Info']\n",
    "\n",
    "# Assuming mismatches could be empty if no matches of 1 are found\n",
    "if not mismatches_info.empty:\n",
    "    # Count the frequency of each specific mismatch case\n",
    "    mismatch_counts = mismatches_info.value_counts()\n",
    "\n",
    "    # Export the mismatch counts to a CSV file\n",
    "    mismatch_counts.to_csv('mismatch_frequencies_detailed.csv')\n",
    "    print(\"Mismatch frequency data with detailed unmatched HLA-LA alleles has been exported to 'mismatch_frequencies_detailed.csv'.\")\n",
    "else:\n",
    "    print(\"No mismatch data found for the case where Match Count is 1.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e9e1e6-a850-4bc0-af59-4fea8c2fea18",
   "metadata": {},
   "source": [
    "# Test if any frequent combination missed from Hibag XX sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287003a5-22b8-4b26-8b47-a846ea572b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you've loaded your DataFrame, for example:\n",
    "# HLA = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Filter to find rows with the specific allele combination\n",
    "specific_combination = HLA[\n",
    "    ((HLA['hibag.DQA1.1'] == '5:01:00') | (HLA['hibag.DQA1.2'] == '5:01:00')) &\n",
    "    ((HLA['hibag.DQB1.1'] == '3:01:00') | (HLA['hibag.DQB1.2'] == '3:01:00'))\n",
    "]\n",
    "\n",
    "# Count the number of rows that match this criteria\n",
    "combination_count = len(specific_combination)\n",
    "print(f\"The number of samples with HLA-DQA1*05:01 and HLA-DQB1*03:01 is: {combination_count}\")\n",
    "\n",
    "# Optionally, export the filtered DataFrame to a CSV file\n",
    "specific_combination.to_csv('specific_allele_combination_samples.csv', index=False)\n",
    "print(\"Filtered data has been exported to 'specific_allele_combination_samples.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97e048-f56a-42fc-8720-c3b9a395606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you've loaded your DataFrame, for example:\n",
    "# HLA = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Define the specific alleles for DQA1 and DQB1\n",
    "dqa1_alleles = ['5:01:00', '5:05:00']\n",
    "dqb1_alleles = ['2:01:00', '2:02:00']\n",
    "\n",
    "# Filter to find rows with the specific allele combinations\n",
    "specific_combination = HLA[\n",
    "    (HLA['hibag.DQA1.1'].isin(dqa1_alleles) | HLA['hibag.DQA1.2'].isin(dqa1_alleles)) &\n",
    "    (HLA['hibag.DQB1.1'].isin(dqb1_alleles) | HLA['hibag.DQB1.2'].isin(dqb1_alleles))\n",
    "]\n",
    "\n",
    "# Count the number of rows that match these criteria\n",
    "combination_count = len(specific_combination)\n",
    "print(f\"The number of samples with specified HLA-DQA1 and HLA-DQB1 alleles is: {combination_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ae8ec-c41f-4654-ae2e-30a3be655425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you've loaded your DataFrame, for example:\n",
    "# HLA = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Define the specific alleles for DQA1 and DQB1\n",
    "dqa1_alleles = ['5:01:00', '5:05:00']\n",
    "dqb1_alleles = ['3:01:00', '2:02:00','2:01:00']\n",
    "\n",
    "# Filter to find rows with the genotype 'XX' and the specific allele combinations\n",
    "specific_combination = HLA[\n",
    "    (HLA['hibag.genotype'] == 'X/X') &  HLA['hibag.genotype'].notna() &\n",
    "    (HLA['hibag.DQA1.1'].isin(dqa1_alleles) | HLA['hibag.DQA1.2'].isin(dqa1_alleles)) &\n",
    "    (HLA['hibag.DQB1.1'].isin(dqb1_alleles) | HLA['hibag.DQB1.2'].isin(dqb1_alleles))\n",
    "]\n",
    "\n",
    "# Count the number of rows that match these criteria\n",
    "combination_count = len(specific_combination)\n",
    "print(f\"The number of XX genotype samples with specified HLA-DQA1 and HLA-DQB1 alleles is: {combination_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceaa86d-173b-421e-9a69-083c4807b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hibag_xx = HLA[(HLA['hibag.genotype'] == 'X/X') & HLA['hibag.genotype'].notna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d1d45-1968-40f9-811d-5d89ea04ea3e",
   "metadata": {},
   "source": [
    "# This is the one to make all the HLA calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f2a284-3cce-455e-8f2f-f5c842d2ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame HLA is already loaded\n",
    "# For example: HLA = pd.read_csv('your_data.csv')\n",
    "\n",
    "def check_combinations(row):\n",
    "    # Initialize the new columns\n",
    "    row['DQ2.5'], row['DQ2.2'], row['DQ7.5'], row['DQ8.1'] = 'negative', 'negative', 'negative', 'negative'\n",
    "    \n",
    "    # Condition for DQ2.5\n",
    "    if (('5:01:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']] and '2:01:00' in [row['hibag.DQB1.1'], row['hibag.DQB1.2']]) or\n",
    "        ('5:01:00' in [row['hla.la.DQA1.1'], row['hla.la.DQA1.2']] and '2:01:00' in [row['hla.la.DQB1.1'], row['hla.la.DQB1.2']])):\n",
    "        row['DQ2.5'] = 'positive'\n",
    "        \n",
    "    # Condition for DQ2.2\n",
    "    if ('2:02:00' in [row['hibag.DQB1.1'], row['hibag.DQB1.2']] and \n",
    "        ('3:01:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']] or '2:01:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']])):\n",
    "        row['DQ2.2'] = 'positive'\n",
    "\n",
    "    # Condition for DQ7.5\n",
    "    if (('5:01:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']] or '5:05:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']]) and\n",
    "        '3:01:00' in [row['hibag.DQB1.1'], row['hibag.DQB1.2']]):\n",
    "        row['DQ7.5'] = 'positive'\n",
    "\n",
    "    # Condition for DQ8.1\n",
    "    if ((('3:01:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']] or '3:03:00' in [row['hibag.DQA1.1'], row['hibag.DQA1.2']] )and '3:02:00' in [row['hibag.DQB1.1'], row['hibag.DQB1.2']]) or\n",
    "        (row['hla.la.DQA1.2'] == '3:01:00' and row['hla.la.DQB1.1'] == '3:02:00')):\n",
    "        row['DQ8.1'] = 'positive'\n",
    "    \n",
    "    # Combining genotype risks into a single column\n",
    "    genotypes = []\n",
    "    if row['DQ2.5'] == 'positive':\n",
    "        genotypes.append('2.5')\n",
    "    if row['DQ2.2'] == 'positive':\n",
    "        genotypes.append('2.2')\n",
    "    if row['DQ7.5'] == 'positive':\n",
    "        genotypes.append('7.5')\n",
    "    if row['DQ8.1'] == 'positive':\n",
    "        genotypes.append('8.1')\n",
    "    \n",
    "    row['genotype'] = '/'.join(genotypes) if genotypes else 'X'\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Apply the function across the DataFrame\n",
    "HLA = HLA.apply(check_combinations, axis=1)\n",
    "\n",
    "# Define columns to keep\n",
    "columns_to_keep = [\n",
    "    'person_id', 'CeD', 'race', 'ethnicity', 'sex_at_birth', 'age', 'tag.genotype',\n",
    "    'hibag.DQA1.1', 'hibag.DQA1.2', 'hibag.DQB1.1', 'hibag.DQB1.2', \n",
    "    'hibag.DRB1.1', 'hibag.DRB1.2', 'hibag.genotype', \n",
    "    'hla.la.DQA1.1', 'hla.la.DQA1.2', 'hla.la.DQB1.1', 'hla.la.DQB1.2', \n",
    "    'hla.la.DRB1.1', 'hla.la.DRB1.2', 'hla.la.genotype', \n",
    "    'DQ2.5', 'DQ2.2', 'DQ7.5', 'DQ8.1', 'genotype'\n",
    "]\n",
    "\n",
    "# Select only the specified columns\n",
    "final_data = HLA[columns_to_keep]\n",
    "\n",
    "# Export the selected columns and filtered data to a CSV file\n",
    "final_data.to_csv('final_filtered_data.csv', index=False)\n",
    "print(\"Final filtered data has been exported to 'final_filtered_data.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d32612-7939-4472-94a4-e1434c69a359",
   "metadata": {},
   "source": [
    "# Analyze HLA data for the manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22fc51-9d0b-4d64-8a77-e749d30a04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path2 = 'final_filtered_data.csv'\n",
    "HLA = pd.read_csv(file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d5bb84-a6d6-4146-a697-8434b5dca890",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA.loc[HLA['hibag.genotype'] == 'DQ2.5/DQ2.5', 'XF_genotype'] = '2.5/2.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7bc409-10d5-406e-8d5b-aa5654d79c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA.loc[HLA['hibag.genotype'] == 'DQ7.5/DQ7.5', 'XF_genotype'] = '7.5/7.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a688df-3e86-4a44-ad0b-0b50ad343795",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(HLA[HLA['hibag.genotype'] == 'DQ7.5/DQ7.5'][['hibag.genotype', 'XF_genotype']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d892e48-994f-43f6-90e5-49491c253fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA.loc[HLA['hibag.genotype'] == 'DQ2.2/DQ2.2', 'XF_genotype'] = '2.2/2.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343a905-2961-4e64-805a-8375cb8b132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(HLA[HLA['hibag.genotype'] == 'DQ2.2/DQ2.2'][['hibag.genotype', 'XF_genotype']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d06ac03-acc1-4c2b-b2f3-d2374d2009e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA.loc[HLA['hibag.genotype'] == 'DQ8/DQ8', 'XF_genotype'] = '8.1/8.1'\n",
    "print(HLA[HLA['hibag.genotype'] == 'DQ8/DQ8'][['hibag.genotype', 'XF_genotype']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d972e8-2b51-4df2-880f-b30cb324f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genotype_mapping = {\n",
    "    'X': 'X/X',\n",
    "    '8.1': '8.1/X',\n",
    "    '2.5': '2.5/X',\n",
    "    '7.5': '7.5/X',\n",
    "    '2.2': '2.2/X',\n",
    "    '2.5/2.2/7.5': '2.2/7.5'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666cbba2-2874-42cb-9f59-cbf8c795ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mapping to the 'XF_genotype' column\n",
    "HLA['XF_genotype'] = HLA['XF_genotype'].replace(genotype_mapping)\n",
    "\n",
    "# Optionally, verify the updates or check some of the transformed entries\n",
    "print(HLA[['hibag.genotype', 'XF_genotype']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ancestry\n",
    "ancestry = pd.read_csv(f'{bucket}/data/ancestry_preds.tsv', sep='\\t')\n",
    "ancestry.rename(columns={'research_id':'person_id'},inplace=True)\n",
    "HLA = pd.merge(HLA, ancestry[['person_id','ancestry_pred']], on='person_id', how='inner')\n",
    "\n",
    "demo = pd.read_csv('ced_matched_data_v2.csv')\n",
    "cols_pc=[col for col in demo.columns if col.startswith('PC')]\n",
    "cols_pc.append(['person_id'])\n",
    "HLA = pd.merge(HLA,demo,on='person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920f9ab6-a984-4e9c-90c6-26a060c66eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the changes back to a CSV file if needed\n",
    "HLA.to_csv('updated_HLA.csv', index=False)\n",
    "print(\"Updated data has been exported to 'updated_HLA.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
